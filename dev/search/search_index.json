{
    "docs": [
        {
            "location": "/", 
            "text": "Introduction\n\n\n\n\nPredicting timeseries of chaotic systems can be a very difficult task. Most methods employed for such a feat are typically relying on large neural networks and machine learning. One does not need them though! In the package \nTimeseriesPrediction\n we are presenting methods that instead take advantage of dynamical systems theory. Many such methods exist, like for example \nCluster weighted modelling\n or \nnetworks of dynamical systems\n. The first method included in \nTimeseriesPrediction\n, which is also simplest one, is called \"local modelling\".\n\n\n\n\nLocal Modelling\n\n\nLocal modelling predicts timeseries using a delay embedded state space reconstruction. It finds the nearest neighbors of a query point within this reconstructed space and applies a local model to make a prediction. \"Local\" model refers to the fact that the images (future points) of the neighborhood of a point are the only component used to make a prediction.\n\n\nIn contrast to typical neural networks applications, there is no training happening in this approach. A given timeseries dataset constitutes a pool of points one uses to make predictions from.\n\n\n\n\nAvailable Functionality\n\n\n\n\nLocal Models\n\n\nTimeseriesPrediction\n has two local models (usable in any prediction scheme). See \nAbstractLocalModel\n for more details.\n\n\n\n\nTimeseries Prediction\n\n\nlocalmodel_tsp\n predicts the future of one or many (univariate) timeseries. The details are in the \ntimeseries prediction page\n.\n\n\n\n\nSpatio-Temporal Timeseries\n\n\nOne of the biggest strengths of \nTimeseriesPrediction\n is a robust, simple, and feature-rich interface that can predict the evolution of spatio-temporal systems (commonly represented by PDEs or by \"map lattices\" (coupled maps)). To see the full interface please visit the \nspatio-temporal prediction page\n. In addition, the \nspatio-temporal examples\n page is full of runnable code that displays the capabilities of spatio-temporal prediction of \nTimeseriesPrediction\n.", 
            "title": "Introduction"
        }, 
        {
            "location": "/#introduction", 
            "text": "Predicting timeseries of chaotic systems can be a very difficult task. Most methods employed for such a feat are typically relying on large neural networks and machine learning. One does not need them though! In the package  TimeseriesPrediction  we are presenting methods that instead take advantage of dynamical systems theory. Many such methods exist, like for example  Cluster weighted modelling  or  networks of dynamical systems . The first method included in  TimeseriesPrediction , which is also simplest one, is called \"local modelling\".", 
            "title": "Introduction"
        }, 
        {
            "location": "/#local-modelling", 
            "text": "Local modelling predicts timeseries using a delay embedded state space reconstruction. It finds the nearest neighbors of a query point within this reconstructed space and applies a local model to make a prediction. \"Local\" model refers to the fact that the images (future points) of the neighborhood of a point are the only component used to make a prediction.  In contrast to typical neural networks applications, there is no training happening in this approach. A given timeseries dataset constitutes a pool of points one uses to make predictions from.", 
            "title": "Local Modelling"
        }, 
        {
            "location": "/#available-functionality", 
            "text": "", 
            "title": "Available Functionality"
        }, 
        {
            "location": "/#local-models", 
            "text": "TimeseriesPrediction  has two local models (usable in any prediction scheme). See  AbstractLocalModel  for more details.", 
            "title": "Local Models"
        }, 
        {
            "location": "/#timeseries-prediction", 
            "text": "localmodel_tsp  predicts the future of one or many (univariate) timeseries. The details are in the  timeseries prediction page .", 
            "title": "Timeseries Prediction"
        }, 
        {
            "location": "/#spatio-temporal-timeseries", 
            "text": "One of the biggest strengths of  TimeseriesPrediction  is a robust, simple, and feature-rich interface that can predict the evolution of spatio-temporal systems (commonly represented by PDEs or by \"map lattices\" (coupled maps)). To see the full interface please visit the  spatio-temporal prediction page . In addition, the  spatio-temporal examples  page is full of runnable code that displays the capabilities of spatio-temporal prediction of  TimeseriesPrediction .", 
            "title": "Spatio-Temporal Timeseries"
        }, 
        {
            "location": "/localmodels/", 
            "text": "Local Modeling\n\n\n\n\nReconstruction parameters\n\n\nDon't forget that \nDynamicalSystems.jl\n also has functions for estimating good parameters for delay embedding: \nestimate_delay\n and \nestimate_dimension\n.\n\n\n\n\n\n\nLocal Model Prediction\n\n\n#\n\n\nTimeseriesPrediction.localmodel_tsp\n \n \nFunction\n.\n\n\nlocalmodel_tsp\n(\ns\n,\n \n\u03b3\n::\nInt\n,\n \n\u03c4\n,\n \np\n::\nInt\n;\n \nmethod\n,\n \nntype\n,\n \nstepsize\n)\n\n\nlocalmodel_tsp\n(\ns\n,\n \np\n::\nInt\n;\n \nmethod\n,\n \nntype\n,\n \nstepsize\n)\n\n\n\n\n\n\nPerform a timeseries prediction for \np\n points, using local weighted modeling [1]. The function always returns an object of the same type as \ns\n, which can be either a timeseries (vector) or an \nAbstractDataset\n (trajectory), and the returned data always contains the final point of \ns\n as starting point. This means that the returned data has length of \np + 1\n.\n\n\nIf given \n(s, \u03b3, \u03c4)\n, it first calls \nreconstruct\n (from \nDelayEmbeddings\n) on \ns\n with \n(\u03b3, \u03c4)\n. If given only \ns\n then no reconstruction is done.\n\n\nKeyword Arguments\n\n\n\n\nmethod = AverageLocalModel(\u03c9_unsafe)\n : Subtype of \nAbstractLocalModel\n.\n\n\nntype = FixedMassNeighborhood(2)\n : Subtype of \nAbstractNeighborhood\n (from \nDelayEmbeddings\n).\n\n\nstepsize = 1\n : Prediction step size.\n\n\n\n\nDescription\n\n\nGiven a query point, the function finds its neighbors using neighborhood \nntype\n. Then, the neighbors \nxnn\n and their images \nynn\n are used to make a prediction for the future of the query point, using the provided \nmethod\n. The images \nynn\n are the points \nxnn\n shifted by \nstepsize\n into the future.\n\n\nThe algorithm is applied iteratively until a prediction of length \np\n has been created, starting with the query point to be the last point of the timeseries.\n\n\nReferences\n\n\n[1] : D. Engster \n U. Parlitz, \nHandbook of Time Series Analysis\n Ch. 1, VCH-Wiley (2006)\n\n\nsource\n\n\n#\n\n\nTimeseriesPrediction.AbstractLocalModel\n \n \nType\n.\n\n\nAbstractLocalModel\n\n\n\n\n\n\nSupertype of methods for making a prediction of a query point \nq\n using local models, following the methods of [1]. Concrete subtypes are \nAverageLocalModel\n and \nLinearLocalModel\n.\n\n\nAll models weight neighbors with a chosen function, so that distant neighbors have smaller impact on the prediction and so that the interpolation is smooth. The default weighting function we use is\n\n\n\n\n\n\\begin{aligned}\n\u03c9_i(d_i,d_{max}) = \\left[ 1- \\left(\\frac{d_i}{d_{max}}\\right)^2\\right]^4\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\u03c9_i(d_i,d_{max}) = \\left[ 1- \\left(\\frac{d_i}{d_{max}}\\right)^2\\right]^4\n\\end{aligned}\n\n\n\n\n\nwith \nd_i = ||x_{nn,i} -q||_2\nd_i = ||x_{nn,i} -q||_2\n being the distance of each neighbor from the query point.\n\n\nYou can also provide your own function or give \n\u03c9_safe(d, dmax) = dmax \n 0 ? (1.1 - (d/dmax)^2)^4 : 1.0\n for a safe version of \n\u03c9\n\u03c9\n that takes into acount edge cases. Finally you can also give \nnothing\n in place of \n\u03c9\n. In that case no weighting is done and direct average of neighbors is returned.\n\n\nAverage Local Model\n\n\nAverageLocalModel\n(\n\u03c9\n)\n\n\n\n\n\n\nThe prediction is simply the weighted average of the images \ny_{nn, i}\ny_{nn, i}\n of the neighbors \nx_{nn, i}\nx_{nn, i}\n of the query point \nq\n, weighting using given function \n\u03c9\n\n\n\n\n\n\\begin{aligned}\ny_{pred} = \\frac{\\sum{\\omega_i y_{nn,i}}}{\\sum{\\omega_i}}\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\ny_{pred} = \\frac{\\sum{\\omega_i y_{nn,i}}}{\\sum{\\omega_i}}\n\\end{aligned}\n\n\n\n\n\nLinear Local Model\n\n\nLinearLocalModel\n([\n\u03c9\n \n],\n \n\u03bc\n::\nReal\n=\n2\n.])\n\n\nLinearLocalModel\n([\n\u03c9\n \n],\n \ns_min\n::\nReal\n,\n \ns_max\n::\nReal\n)\n\n\n\n\n\n\nThe prediction is a weighted linear regression over the neighbors \nx_{nn, i}\nx_{nn, i}\n of the query and their images \ny_{nn,i}\ny_{nn,i}\n as shown in [1].\n\n\nGiving either \n\u03bc\n or \ns_min\n and \ns_max\n determines which type of regularization is applied.\n\n\n\n\n\n\n\u03bc\n : Ridge Regression\n\n\n\n\n\n\\begin{aligned}\nf(\\sigma) = \\frac{\\sigma^2}{\\mu^2 + \\sigma^2}\n\\end{aligned}\n\n\n  * \ns_min\n, \ns_max\n : Soft Threshold\n\n\n\n\n\n\\begin{aligned}\nf(\\sigma) = \\begin{cases} 0, \n \\sigma \n s_{min}\\\\\n\\left(1 - \\left( \\frac{s_{max}-\\sigma}{s_{max}-s_{min}}\\right)^2 \\right)^2,\n\ns_{min} \\leq \\sigma \\leq s_{max} \\\\\n1, \n \\sigma \n s_{max}\\end{cases}\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\nf(\\sigma) = \\begin{cases} 0, & \\sigma < s_{min}\\\\\n\\left(1 - \\left( \\frac{s_{max}-\\sigma}{s_{max}-s_{min}}\\right)^2 \\right)^2,\n&s_{min} \\leq \\sigma \\leq s_{max} \\\\\n1, & \\sigma > s_{max}\\end{cases}\n\\end{aligned}\n\n\n\n\n\n\n\n\n\nReferences\n\n\n[1] : D. Engster \n U. Parlitz, \nHandbook of Time Series Analysis\n Ch. 1, VCH-Wiley (2006)\n\n\nsource\n\n\n\n\nSingle Timeseries Example\n\n\nWe will predict the future of a (relatively simple) timeseries:\n\n\nusing\n \nTimeseriesPrediction\n \n# re-exports DelayEmbeddings\n\n\nusing\n \nDynamicalSystemsBase\n \n# to access some systems\n\n\n\nds\n \n=\n \nSystems\n.\nroessler\n(\n0.1\nones\n(\n3\n))\n\n\ndt\n \n=\n \n0.1\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n1000\n;\n \ndt\n=\ndt\n)\n\n\nN_train\n \n=\n \n6001\n\n\ns_train\n \n=\n \ndata\n[\n1\n:\nN_train\n,\n \n1\n]\n\n\ns_test\n  \n=\n \ndata\n[\nN_train\n:\nend\n,\n1\n]\n\n\n\nntype\n \n=\n \nFixedMassNeighborhood\n(\n3\n)\n\n\n\np\n \n=\n \n500\n\n\ns_pred\n \n=\n \nlocalmodel_tsp\n(\ns_train\n,\n \n4\n,\n \n15\n,\n \np\n;\n \nntype\n=\nntype\n)\n\n\n\nusing\n \nPyPlot\n\n\nfigure\n()\n\n\nplot\n(\n550\n:\ndt\n:\n600\n,\n \ns_train\n[\n5501\n:\nend\n],\n \nlabel\n \n=\n \ntraining (trunc.)\n,\n \ncolor\n \n=\n \nC1\n)\n\n\nplot\n(\n600\n:\ndt\n:\n(\n600\n+\np\n*\ndt\n),\n \ns_test\n[\n1\n:\np\n+\n1\n],\n \ncolor\n \n=\n \nC3\n,\n \nlabel\n \n=\n \nactual signal\n)\n\n\nplot\n(\n600\n:\ndt\n:\n(\n600\n+\np\n*\ndt\n),\n \ns_pred\n,\n \ncolor\n \n=\n \nC0\n,\n \nls\n=\n--\n,\n \nlabel\n=\npredicted\n)\n\n\n\ntitle\n(\nPool of points: \n$\n(\nN_train\n)\n, predicted points: \n$\n(\np\n)\n)\n\n\nxlabel\n(\n\\$\nt\n\\$\n);\n \nylabel\n(\n\\$\nx\n\\$\n)\n\n\nlegend\n(\nloc\n=\nupper left\n)\n\n\ntight_layout\n()\n\n\n\n\n\n\n\n\n\n\nMultiple Timeseries Example\n\n\nPredicting multivariate timeseries works the same as with scalar timeseries.\n\n\nusing\n \nTimeseriesPrediction\n\n\n\nds\n \n=\n \nSystems\n.\nroessler\n(\nones\n(\n3\n))\n\n\ndt\n \n=\n \n0.1\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n1000\n;\n \ndt\n=\ndt\n)\n\n\nN_train\n \n=\n \n1501\n\n\ns_train\n \n=\n \ndata\n[\n1\n:\nN_train\n,\n \nSVector\n(\n1\n,\n2\n)]\n\n\n#Identical to data[1:N_train, 1:2] but much faster\n\n\ns_test\n  \n=\n \ndata\n[\nN_train\n:\nend\n,\n \nSVector\n(\n1\n,\n2\n)]\n\n\n\np\n \n=\n \n100\n;\n \nstepsize\n \n=\n \n5\n\n\ns_pred_10\n \n=\n \nlocalmodel_tsp\n(\ns_train\n,\n \n3\n,\n \n15\n,\n \np\n;\n  \nstepsize\n \n=\n \nstepsize\n)\n\n\n\nusing\n \nPyPlot\n;\n \nfigure\n(\nfigsize\n=\n(\n12\n,\n6\n))\n\n\n\nidx_prev\n \n=\n \n200\n \n# how many previous points to show\n\n\ntf\n \n=\n \nInt\n((\nN_train\n \n-\n \n1\n)\n*\ndt\n)\n \n# final time of test set\n\n\n\n# Plot real x-coordinate\n\n\nplot\n((\ntf\n \n-\n \nidx_prev\n*\ndt\n)\n:\ndt\n:\ntf\n,\n \ns_train\n[\nN_train\n-\nidx_prev\n:\nend\n,\n1\n],\n\n    \nlabel\n \n=\n \nreal x\n,\n \ncolor\n \n=\n \nC1\n)\n\n\nplot\n(\ntf\n:\ndt\n:\n(\ntf\n+\np\n*\ndt\n*\nstepsize\n),\n \ns_test\n[\n1\n:\np\n*\nstepsize\n+\n1\n,\n1\n],\n \ncolor\n \n=\n \nC1\n)\n\n\n# Plot predicted x-coordinate\n\n\nplot\n(\ntf\n:\ndt\n*\nstepsize\n:\n(\ntf\n+\np\n*\ndt\n*\nstepsize\n),\n \ns_pred_10\n[\n:\n,\n1\n],\n \ncolor\n \n=\n \nC3\n,\n\n\nlw\n=\n0.5\n,\n \nmarker\n=\ns\n,\n \nms\n \n=\n \n4.0\n,\n \nlabel\n=\npred. x\n,\n \nalpha\n \n=\n \n0.75\n)\n\n\n\n# Plot real y-coordinate\n\n\nplot\n((\ntf\n \n-\n \nidx_prev\n*\ndt\n)\n:\ndt\n:\ntf\n,\n \ns_train\n[\nN_train\n-\nidx_prev\n:\nend\n,\n2\n],\n\n    \nlabel\n \n=\n \nreal y\n,\n \ncolor\n \n=\n \nC0\n)\n\n\nplot\n(\ntf\n:\ndt\n:\n(\ntf\n+\np\n*\ndt\n*\nstepsize\n),\n \ns_test\n[\n1\n:\np\n*\nstepsize\n+\n1\n,\n2\n],\n \ncolor\n \n=\n \nC0\n)\n\n\n# Plot predicted y-coordinate\n\n\nplot\n(\ntf\n:\ndt\n*\nstepsize\n:\n(\ntf\n+\np\n*\ndt\n*\nstepsize\n),\n \ns_pred_10\n[\n:\n,\n2\n],\n \ncolor\n \n=\n \nC9\n,\n\n\nlw\n=\n0.5\n,\n \nmarker\n=\ns\n,\n \nms\n \n=\n \n4.0\n,\n \nlabel\n=\npred. y\n,\n \nalpha\n \n=\n \n0.75\n)\n\n\n\n# Plot start of prediction\n\n\nplot\n([\ntf\n,\ntf\n],[\n-\n12\n,\n12\n],\n \n--\n,\n \ncolor\n=\nblack\n,\n \nalpha\n \n=\n \n0.5\n)\n\n\n\ntitle\n(\nPool of points: \n$\n(\nN_train\n)\n, predicted points: \n$\n(\np\n)\n)\n\n\nxlabel\n(\n\\$\nt\n\\$\n);\n \nylabel\n(\n\\$\nx, y\n\\$\n)\n\n\nlegend\n(\nloc\n=\nupper left\n)\n\n\ntight_layout\n()\n\n\n\n\n\n\n\n\n\n\nError Measures\n\n\nBeing able to evaluate model performance without looking at plots can be very helpful when trying to quantify its error as well as finding good parameters in the first place.\n\n\n#\n\n\nTimeseriesPrediction.MSEp\n \n \nFunction\n.\n\n\nMSEp\n(\nR\n::\nAbstractDataset\n{\nD\n,\nT\n},\n \nR_test\n,\n \np\n;\n \nmethod\n,\n \nntype\n,\n \nstepsize\n)\n \n-\n \nerror\n\n\n\n\n\n\nCompute mean squared error of iterated predictions of length \np\n using test set \nR_test\n.\n\n\nDescription\n\n\nThis error measure takes in a prediction model consisting of \nR\n, \nmethod\n, \nntype\n and \nstepsize\n and evaluates its performance. The test set \nR_test\n is a delay reconstruction with the same delay \n\u03c4\n and dimension \nD\n as \nR\n. For each subset of \nR_test\n with length \np\n it calls \nlocalmodel_tsp\n. The model error is then defined as\n\n\n\n\n\n\\begin{aligned}\nMSE_p = \\frac{1}{p|T_{ref}|}\\sum_{t\\in T_{ref}}\\sum_{i=1}^{p} \\left(y_{t+i}\n- y_{pred,t+i} \\right)^2\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\nMSE_p = \\frac{1}{p|T_{ref}|}\\sum_{t\\in T_{ref}}\\sum_{i=1}^{p} \\left(y_{t+i}\n- y_{pred,t+i} \\right)^2\n\\end{aligned}\n\n\n\n\n\nwhere \n|T_{ref}|\n|T_{ref}|\n is the number of subsets of \nR_test\n used.\n\n\nReferences\n\n\nSee \nlocalmodel_tsp\n.\n\n\nsource\n\n\nHere is an example function that employs \nMSEp\n to find good parameters. It takes in a timeseries \ns\n and ranges for the dimensions, delays and number of nearest neighbors to  try. Keyword arguments are \nvalid_len\n, which is the number of prediction steps, and \nnum_tries\n the number of different starting points to choose.\n\n\nIt then calculates \nMSEp\n for all parameter combinations and returns the best parameter set.\n\n\n```@example tspred\nfunction estimate_param(s::AbstractVector,\n    dims, delay, K; valid_len=100, num_tries=50)\n    result = Dict{NamedTuple,Float64}()\n    step = 1\n    for \u03b3 \u2208 dims, \u03c4 \u2208 delay\n        s_train = @view s[1:end-(\u03b3+1)\n\u03c4-valid_len-num_tries-50]\n        s_test = @view s[end-\u03b3\n\u03c4-valid_len-num_tries:end]\n        R = reconstruct(s_train,\u03b3,\u03c4)\n        R_test = reconstruct(s_test,\u03b3,\u03c4)\n        tree = KDTree(R[1:end-1])\n        for k \u2208 K\n            ntype = FixedMassNeighborhood(k)\n            result[(D=D,\u03c4=\u03c4,k=k)] =\n            MSEp(R, tree, R_test, valid_len; ntype=ntype)\n        end\n    end\n    best_param = collect(keys(result))[findmin(collect(values(result)))[2]]\n    return best_param\nend\n\n\nds = Systems.roessler(0.1ones(3))\ndt = 0.1\ndata = trajectory(ds, 1000; dt=dt)\nN_train = 6001\ns_train = data[1:N_train, 1]\ns_test  = data[N_train:end,1]\n\n\nD, \u03c4, k = estimate_param(s_train, 1:4, [10, 15, 30], 2:4)\n```\n\n\n\n\nCool animation!\n\n\nThis is an animation of timeseries prediction of the \nz\n variable of the Roessler system. On the left you can see the time evolution of the whole system with the chaotic attractor indicated in gray. The right side is a plot of the \nz\n component of the system. The actual values are displayed in green. In red you can see the iteratively predicted version. As training set it used part of the attractor shown in gray on the left.", 
            "title": "Local Modeling & Timeseries Prediction"
        }, 
        {
            "location": "/localmodels/#local-modeling", 
            "text": "Reconstruction parameters  Don't forget that  DynamicalSystems.jl  also has functions for estimating good parameters for delay embedding:  estimate_delay  and  estimate_dimension .", 
            "title": "Local Modeling"
        }, 
        {
            "location": "/localmodels/#local-model-prediction", 
            "text": "#  TimeseriesPrediction.localmodel_tsp     Function .  localmodel_tsp ( s ,   \u03b3 :: Int ,   \u03c4 ,   p :: Int ;   method ,   ntype ,   stepsize )  localmodel_tsp ( s ,   p :: Int ;   method ,   ntype ,   stepsize )   Perform a timeseries prediction for  p  points, using local weighted modeling [1]. The function always returns an object of the same type as  s , which can be either a timeseries (vector) or an  AbstractDataset  (trajectory), and the returned data always contains the final point of  s  as starting point. This means that the returned data has length of  p + 1 .  If given  (s, \u03b3, \u03c4) , it first calls  reconstruct  (from  DelayEmbeddings ) on  s  with  (\u03b3, \u03c4) . If given only  s  then no reconstruction is done.  Keyword Arguments   method = AverageLocalModel(\u03c9_unsafe)  : Subtype of  AbstractLocalModel .  ntype = FixedMassNeighborhood(2)  : Subtype of  AbstractNeighborhood  (from  DelayEmbeddings ).  stepsize = 1  : Prediction step size.   Description  Given a query point, the function finds its neighbors using neighborhood  ntype . Then, the neighbors  xnn  and their images  ynn  are used to make a prediction for the future of the query point, using the provided  method . The images  ynn  are the points  xnn  shifted by  stepsize  into the future.  The algorithm is applied iteratively until a prediction of length  p  has been created, starting with the query point to be the last point of the timeseries.  References  [1] : D. Engster   U. Parlitz,  Handbook of Time Series Analysis  Ch. 1, VCH-Wiley (2006)  source  #  TimeseriesPrediction.AbstractLocalModel     Type .  AbstractLocalModel   Supertype of methods for making a prediction of a query point  q  using local models, following the methods of [1]. Concrete subtypes are  AverageLocalModel  and  LinearLocalModel .  All models weight neighbors with a chosen function, so that distant neighbors have smaller impact on the prediction and so that the interpolation is smooth. The default weighting function we use is   \n\\begin{aligned}\n\u03c9_i(d_i,d_{max}) = \\left[ 1- \\left(\\frac{d_i}{d_{max}}\\right)^2\\right]^4\n\\end{aligned}  \n\\begin{aligned}\n\u03c9_i(d_i,d_{max}) = \\left[ 1- \\left(\\frac{d_i}{d_{max}}\\right)^2\\right]^4\n\\end{aligned}   with  d_i = ||x_{nn,i} -q||_2 d_i = ||x_{nn,i} -q||_2  being the distance of each neighbor from the query point.  You can also provide your own function or give  \u03c9_safe(d, dmax) = dmax   0 ? (1.1 - (d/dmax)^2)^4 : 1.0  for a safe version of  \u03c9 \u03c9  that takes into acount edge cases. Finally you can also give  nothing  in place of  \u03c9 . In that case no weighting is done and direct average of neighbors is returned.  Average Local Model  AverageLocalModel ( \u03c9 )   The prediction is simply the weighted average of the images  y_{nn, i} y_{nn, i}  of the neighbors  x_{nn, i} x_{nn, i}  of the query point  q , weighting using given function  \u03c9   \n\\begin{aligned}\ny_{pred} = \\frac{\\sum{\\omega_i y_{nn,i}}}{\\sum{\\omega_i}}\n\\end{aligned}  \n\\begin{aligned}\ny_{pred} = \\frac{\\sum{\\omega_i y_{nn,i}}}{\\sum{\\omega_i}}\n\\end{aligned}   Linear Local Model  LinearLocalModel ([ \u03c9   ],   \u03bc :: Real = 2 .])  LinearLocalModel ([ \u03c9   ],   s_min :: Real ,   s_max :: Real )   The prediction is a weighted linear regression over the neighbors  x_{nn, i} x_{nn, i}  of the query and their images  y_{nn,i} y_{nn,i}  as shown in [1].  Giving either  \u03bc  or  s_min  and  s_max  determines which type of regularization is applied.    \u03bc  : Ridge Regression   \n\\begin{aligned}\nf(\\sigma) = \\frac{\\sigma^2}{\\mu^2 + \\sigma^2}\n\\end{aligned} \n  *  s_min ,  s_max  : Soft Threshold   \n\\begin{aligned}\nf(\\sigma) = \\begin{cases} 0,   \\sigma   s_{min}\\\\\n\\left(1 - \\left( \\frac{s_{max}-\\sigma}{s_{max}-s_{min}}\\right)^2 \\right)^2, s_{min} \\leq \\sigma \\leq s_{max} \\\\\n1,   \\sigma   s_{max}\\end{cases}\n\\end{aligned}  \n\\begin{aligned}\nf(\\sigma) = \\begin{cases} 0, & \\sigma < s_{min}\\\\\n\\left(1 - \\left( \\frac{s_{max}-\\sigma}{s_{max}-s_{min}}\\right)^2 \\right)^2,\n&s_{min} \\leq \\sigma \\leq s_{max} \\\\\n1, & \\sigma > s_{max}\\end{cases}\n\\end{aligned}     References  [1] : D. Engster   U. Parlitz,  Handbook of Time Series Analysis  Ch. 1, VCH-Wiley (2006)  source", 
            "title": "Local Model Prediction"
        }, 
        {
            "location": "/localmodels/#single-timeseries-example", 
            "text": "We will predict the future of a (relatively simple) timeseries:  using   TimeseriesPrediction   # re-exports DelayEmbeddings  using   DynamicalSystemsBase   # to access some systems  ds   =   Systems . roessler ( 0.1 ones ( 3 ))  dt   =   0.1  data   =   trajectory ( ds ,   1000 ;   dt = dt )  N_train   =   6001  s_train   =   data [ 1 : N_train ,   1 ]  s_test    =   data [ N_train : end , 1 ]  ntype   =   FixedMassNeighborhood ( 3 )  p   =   500  s_pred   =   localmodel_tsp ( s_train ,   4 ,   15 ,   p ;   ntype = ntype )  using   PyPlot  figure ()  plot ( 550 : dt : 600 ,   s_train [ 5501 : end ],   label   =   training (trunc.) ,   color   =   C1 )  plot ( 600 : dt : ( 600 + p * dt ),   s_test [ 1 : p + 1 ],   color   =   C3 ,   label   =   actual signal )  plot ( 600 : dt : ( 600 + p * dt ),   s_pred ,   color   =   C0 ,   ls = -- ,   label = predicted )  title ( Pool of points:  $ ( N_train ) , predicted points:  $ ( p ) )  xlabel ( \\$ t \\$ );   ylabel ( \\$ x \\$ )  legend ( loc = upper left )  tight_layout ()", 
            "title": "Single Timeseries Example"
        }, 
        {
            "location": "/localmodels/#multiple-timeseries-example", 
            "text": "Predicting multivariate timeseries works the same as with scalar timeseries.  using   TimeseriesPrediction  ds   =   Systems . roessler ( ones ( 3 ))  dt   =   0.1  data   =   trajectory ( ds ,   1000 ;   dt = dt )  N_train   =   1501  s_train   =   data [ 1 : N_train ,   SVector ( 1 , 2 )]  #Identical to data[1:N_train, 1:2] but much faster  s_test    =   data [ N_train : end ,   SVector ( 1 , 2 )]  p   =   100 ;   stepsize   =   5  s_pred_10   =   localmodel_tsp ( s_train ,   3 ,   15 ,   p ;    stepsize   =   stepsize )  using   PyPlot ;   figure ( figsize = ( 12 , 6 ))  idx_prev   =   200   # how many previous points to show  tf   =   Int (( N_train   -   1 ) * dt )   # final time of test set  # Plot real x-coordinate  plot (( tf   -   idx_prev * dt ) : dt : tf ,   s_train [ N_train - idx_prev : end , 1 ], \n     label   =   real x ,   color   =   C1 )  plot ( tf : dt : ( tf + p * dt * stepsize ),   s_test [ 1 : p * stepsize + 1 , 1 ],   color   =   C1 )  # Plot predicted x-coordinate  plot ( tf : dt * stepsize : ( tf + p * dt * stepsize ),   s_pred_10 [ : , 1 ],   color   =   C3 ,  lw = 0.5 ,   marker = s ,   ms   =   4.0 ,   label = pred. x ,   alpha   =   0.75 )  # Plot real y-coordinate  plot (( tf   -   idx_prev * dt ) : dt : tf ,   s_train [ N_train - idx_prev : end , 2 ], \n     label   =   real y ,   color   =   C0 )  plot ( tf : dt : ( tf + p * dt * stepsize ),   s_test [ 1 : p * stepsize + 1 , 2 ],   color   =   C0 )  # Plot predicted y-coordinate  plot ( tf : dt * stepsize : ( tf + p * dt * stepsize ),   s_pred_10 [ : , 2 ],   color   =   C9 ,  lw = 0.5 ,   marker = s ,   ms   =   4.0 ,   label = pred. y ,   alpha   =   0.75 )  # Plot start of prediction  plot ([ tf , tf ],[ - 12 , 12 ],   -- ,   color = black ,   alpha   =   0.5 )  title ( Pool of points:  $ ( N_train ) , predicted points:  $ ( p ) )  xlabel ( \\$ t \\$ );   ylabel ( \\$ x, y \\$ )  legend ( loc = upper left )  tight_layout ()", 
            "title": "Multiple Timeseries Example"
        }, 
        {
            "location": "/localmodels/#error-measures", 
            "text": "Being able to evaluate model performance without looking at plots can be very helpful when trying to quantify its error as well as finding good parameters in the first place.  #  TimeseriesPrediction.MSEp     Function .  MSEp ( R :: AbstractDataset { D , T },   R_test ,   p ;   method ,   ntype ,   stepsize )   -   error   Compute mean squared error of iterated predictions of length  p  using test set  R_test .  Description  This error measure takes in a prediction model consisting of  R ,  method ,  ntype  and  stepsize  and evaluates its performance. The test set  R_test  is a delay reconstruction with the same delay  \u03c4  and dimension  D  as  R . For each subset of  R_test  with length  p  it calls  localmodel_tsp . The model error is then defined as   \n\\begin{aligned}\nMSE_p = \\frac{1}{p|T_{ref}|}\\sum_{t\\in T_{ref}}\\sum_{i=1}^{p} \\left(y_{t+i}\n- y_{pred,t+i} \\right)^2\n\\end{aligned}  \n\\begin{aligned}\nMSE_p = \\frac{1}{p|T_{ref}|}\\sum_{t\\in T_{ref}}\\sum_{i=1}^{p} \\left(y_{t+i}\n- y_{pred,t+i} \\right)^2\n\\end{aligned}   where  |T_{ref}| |T_{ref}|  is the number of subsets of  R_test  used.  References  See  localmodel_tsp .  source  Here is an example function that employs  MSEp  to find good parameters. It takes in a timeseries  s  and ranges for the dimensions, delays and number of nearest neighbors to  try. Keyword arguments are  valid_len , which is the number of prediction steps, and  num_tries  the number of different starting points to choose.  It then calculates  MSEp  for all parameter combinations and returns the best parameter set.  ```@example tspred\nfunction estimate_param(s::AbstractVector,\n    dims, delay, K; valid_len=100, num_tries=50)\n    result = Dict{NamedTuple,Float64}()\n    step = 1\n    for \u03b3 \u2208 dims, \u03c4 \u2208 delay\n        s_train = @view s[1:end-(\u03b3+1) \u03c4-valid_len-num_tries-50]\n        s_test = @view s[end-\u03b3 \u03c4-valid_len-num_tries:end]\n        R = reconstruct(s_train,\u03b3,\u03c4)\n        R_test = reconstruct(s_test,\u03b3,\u03c4)\n        tree = KDTree(R[1:end-1])\n        for k \u2208 K\n            ntype = FixedMassNeighborhood(k)\n            result[(D=D,\u03c4=\u03c4,k=k)] =\n            MSEp(R, tree, R_test, valid_len; ntype=ntype)\n        end\n    end\n    best_param = collect(keys(result))[findmin(collect(values(result)))[2]]\n    return best_param\nend  ds = Systems.roessler(0.1ones(3))\ndt = 0.1\ndata = trajectory(ds, 1000; dt=dt)\nN_train = 6001\ns_train = data[1:N_train, 1]\ns_test  = data[N_train:end,1]  D, \u03c4, k = estimate_param(s_train, 1:4, [10, 15, 30], 2:4)\n```", 
            "title": "Error Measures"
        }, 
        {
            "location": "/localmodels/#cool-animation", 
            "text": "This is an animation of timeseries prediction of the  z  variable of the Roessler system. On the left you can see the time evolution of the whole system with the chaotic attractor indicated in gray. The right side is a plot of the  z  component of the system. The actual values are displayed in green. In red you can see the iteratively predicted version. As training set it used part of the attractor shown in gray on the left.", 
            "title": "Cool animation!"
        }, 
        {
            "location": "/spatiotemporal/", 
            "text": "Spatiotemporal Timeseries Prediction\n\n\nAn application and extension of \nlocal modeling\n to spatiotemporal timeseries.\n\n\n\n\nExamples\n\n\nSeveral example scripts can be found in \nTimeseriesPrediction/examples\n. These examples are run in the \nexamples\n page.\n\n\n\n\n\n\nSpatio-Temporal Embeddings\n\n\nsome info here.\n\n\n#\n\n\nDelayEmbeddings.reconstruct\n \n \nFunction\n.\n\n\nreconstruct\n(\ns\n::\nAbstractArray\n{\n:\nAbstractArray\n{\nT\n,\n\u03a6\n}},\n \nem\n)\n\n\n\n\n\n\nReconstruct the spatial timeseries \ns\n represented by a \nVector\n of \nAbstractArray\n states using the embedding struct \nem\n of type \nAbstractSpatialEmbedding\n.\n\n\nReturns the reconstruction in the form of a \nDataset\n (from \nDelayEmbeddings\n) where each row is a reconstructed state and they are ordered first through linear indexing into each state and then incrementing in time.\n\n\nsource\n\n\n#\n\n\nTimeseriesPrediction.AbstractSpatialEmbedding\n \n \nType\n.\n\n\nAbstractSpatialEmbedding\n \n:\n \nAbstractEmbedding\n\n\n\n\n\n\nSuper-type of spatiotemporal embedding methods. Valid subtypes:\n\n\n\n\nSpatioTemporalEmbedding\n\n\nPCAEmbedding\n\n\n\n\nsource\n\n\n#\n\n\nTimeseriesPrediction.SpatioTemporalEmbedding\n \n \nType\n.\n\n\nSpatioTemporalEmbedding\n{\n\u03a6\n,\nBC\n,\nX\n}\n \n\u2192\n \nembedding\n\n\n\n\n\n\nA spatio temporal delay coordinates structure to be used as a functor. Applies to data of \n\u03a6\n spatial dimensions and gives an embedding of dimensionality \nX\n.\n\n\nembedding\n(\nrvec\n,\n \ns\n,\n \nt\n,\n \n\u03b1\n)\n\n\n\n\n\n\nOperates inplace on \nrvec\n (of length \nX\n) and reconstructs vector from spatial timeseries \ns\n at timestep \nt\n and cartesian index \n\u03b1\n. Note that there are no bounds checks for \nt\n.\n\n\nIt is assumed that \ns\n is a \nVector{\n:AbstractArray{T,\u03a6}}\n.\n\n\nConstructors\n\n\nThere are some convenience constructors that return intuitive embeddings here:\n\n\n\n\ncubic_shell_embedding\n\n\nlight_cone_embedding\n\n\n\n\nThe \"main\" constructor is\n\n\nSpatioTemporalEmbedding\n{\nX\n}\n(\n\u03c4\n,\n \n\u03b2\n,\n \nbc\n,\n \nfsize\n)\n\n\n\n\n\n\nwhich allows full control over the spatio-temporal embedding.\n\n\n\n\n\u03a7 == length(\u03c4) == length(\u03b2)\n : dimensionality of resulting reconstructed space.\n\n\n\u03c4::Vector{Int}\n = Vector of temporal delays \nfor each entry\n of the reconstructed space (sorted in ascending order).\n\n\n\u03b2::Vector{CartesianIndex{\u03a6}}\n = vector of \nrelative\n indices of spatial delays \nfor each entry\n of the reconstructed space.\n\n\nbc::BC\n : boundary condition.\n\n\nfsize::NTuple{\u03a6, Int}\n : Size of each state in the timeseries.\n\n\n\n\nFor example, if you want to have spatial neighbors [0, \u00b11] for time delays \u03c4 = 2, 4, then\n\n\n\u03c4\n \n=\n \n[\n2\n,\n2\n,\n2\n,\n4\n,\n4\n,\n4\n]\n\n\n\u03b2\n \n=\n \nCartesianIndex\n.([\n1\n,\n \n0\n,\n \n-\n1\n,\n \n1\n,\n \n0\n,\n \n-\n1\n])\n\n\n\n\n\n\nsource\n\n\n#\n\n\nTimeseriesPrediction.cubic_shell_embedding\n \n \nFunction\n.\n\n\ncubic_shell_embedding\n(\ns\n,\n \n\u03b3\n,\n \n\u03c4\n,\n \nB\n,\n \nk\n,\n \nbc\n=\nPeriodicBoundary\n())\n \n\u2192\n \nembedding\n\n\n\n\n\n\nCreate a \nSpatioTemporalEmbedding\n instance that includes spatial neighbors in hypercubic \nshells\n. The embedding is to be used with data from \ns\n.\n\n\nDescription\n\n\nPoints are participating in the embedding by forming hypercubic shells around the current point. The total shells formed are \nB\n. The points on the shells have spatial distance \nk \u2265 1\n (distance in indices, like a cityblock metric). \nk = 1\n means that all points of the shell participate. The points of the hypercubic grid can be separated by \nk \u2265 1\n points apart (i.e. dropping \nk-1\n in-between points). In short, in each spatial dimension of the system the cartesian offset indices are \n-B*k : k : k*B\n.\n\n\n\u03b3\n is the number of temporal steps in the past to be included in the embedding, where each step in the past has additional delay time \n\u03c4::Int\n. \n\u03b3=0\n corresponds to using only the present. Notice that \nall\n embedded time frames have the same spatial structure, in contrast to \nlight_cone_embedding\n.\n\n\nAs an example, consider one of the \n\u03b3\n embedded frames (all are the same) of a system with 2 spatial dimensions (\n\u25a1\n = current point, (included \nby definition\n in the embedding), \nn\n = included points in the embedding coming from \nn\n-th shell, \n.\n = points not included in the embedding)\n\n\n      \nB\n \n=\n \n2\n,\n  \nk\n \n=\n \n1\n        \n|\n        \nB\n \n=\n \n1\n,\n  \nk\n \n=\n \n2\n        \n|\n        \nB\n \n=\n \n2\n,\n  \nk\n \n=\n \n2\n\n                           \n|\n                             \n|\n\n\n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n|\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n|\n  \n2\n  \n.\n  \n2\n  \n.\n  \n2\n  \n.\n  \n2\n  \n.\n  \n2\n\n\n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n|\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n|\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n\n\n.\n  \n.\n  \n2\n  \n2\n  \n2\n  \n2\n  \n2\n  \n.\n  \n.\n  \n|\n  \n.\n  \n.\n  \n1\n  \n.\n  \n1\n  \n.\n  \n1\n  \n.\n  \n.\n  \n|\n  \n2\n  \n.\n  \n1\n  \n.\n  \n1\n  \n.\n  \n1\n  \n.\n  \n2\n\n\n.\n  \n.\n  \n2\n  \n1\n  \n1\n  \n1\n  \n2\n  \n.\n  \n.\n  \n|\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n|\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n\n\n.\n  \n.\n  \n2\n  \n1\n  \n\u25a1\n  \n1\n  \n2\n  \n.\n  \n.\n  \n|\n  \n.\n  \n.\n  \n1\n  \n.\n  \n\u25a1\n  \n.\n  \n1\n  \n.\n  \n.\n  \n|\n  \n2\n  \n.\n  \n1\n  \n.\n  \n\u25a1\n  \n.\n  \n1\n  \n.\n  \n2\n\n\n.\n  \n.\n  \n2\n  \n1\n  \n1\n  \n1\n  \n2\n  \n.\n  \n.\n  \n|\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n|\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n\n\n.\n  \n.\n  \n2\n  \n2\n  \n2\n  \n2\n  \n2\n  \n.\n  \n.\n  \n|\n  \n.\n  \n.\n  \n1\n  \n.\n  \n1\n  \n.\n  \n1\n  \n.\n  \n.\n  \n|\n  \n2\n  \n.\n  \n1\n  \n.\n  \n1\n  \n.\n  \n1\n  \n.\n  \n2\n\n\n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n|\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n|\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n\n\n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n|\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n.\n  \n|\n  \n2\n  \n.\n  \n2\n  \n.\n  \n2\n  \n.\n  \n2\n  \n.\n  \n2\n\n\n\n\n\n\nsource\n\n\n#\n\n\nTimeseriesPrediction.light_cone_embedding\n \n \nFunction\n.\n\n\nlight_cone_embedding\n(\ns\n,\n \n\u03b3\n,\n \n\u03c4\n,\n \nr0\n,\n \nc\n,\n \nbc\n=\nPeriodicBoundary\n())\n \n\u2192\n \nembedding\n\n\n\n\n\n\nCreate a \nSpatioTemporalEmbedding\n instance that includes spatial and temporal neighbors of a point based on the notion of a \nlight cone\n.\n\n\nThe embedding is to be used with data from \ns\n.\n\n\nDescription\n\n\nInformation does not travel instantly but with some finite speed \nc \u2265 0.0\n. This constructor creates a cone-like embedding including all points in space and time, whose value can influence a prediction based on the information speed \nc\n. \n\u03b3\n is the number of temporal steps in the past to be included in the embedding, where each step in the past has additional delay time \n\u03c4::Int\n. \n\u03b3=0\n corresponds to using only the present. \nr0\n is the initial radius at the top of the cone, i.e. the radius of influence at the present. \nbc\n is the boundary condition.\n\n\nThe radius of the light cone evolves as: \nr_i = i*\u03c4*c + r0\n for each step \ni \u2208 0:\u03b3\n.\n\n\nAs an example, in a one-dimensional system with \n\u03b3 = 1, \u03c4 = 2, r0 = 1\n, the embedding looks like (\n\u25a1\n = current point (included \nby definition\n in the embedding), \no\n point to be predicted using \ntemporalprediction\n, \nx\n = points included in the embedding, \n.\n = points not included in the embedding)\n\n\ntime\n  \n|\n \nc\n \n=\n \n1\n.\n0\n               \n|\n \nc\n \n=\n \n2\n.\n0\n               \n|\n \nc\n \n=\n \n0\n.\n0\n\n\n\nn\n \n+\n \n1\n \n|\n \n..........\no\n..........\n \n|\n \n..........\no\n..........\n \n|\n \n..........\no\n..........\n\n\nn\n     \n|\n \n.........\nx\n\u25a1\nx\n.........\n \n|\n \n.........\nx\n\u25a1\nx\n.........\n \n|\n \n.........\nx\n\u25a1\nx\n.........\n\n\nn\n \n-\n \n1\n \n|\n \n.....................\n \n|\n \n.....................\n \n|\n \n.....................\n\n\nn\n \n-\n \n\u03c4\n \n|\n \n.......\nxxxxxxx\n.......\n \n|\n \n.....\nxxxxxxxxxx\n......\n \n|\n \n.........\nxxx\n.........\n\n\n\n\n\n\nBesides this example, in the official documentation we show a function \nexplain_light_cone\n which produces a plot of the light cone for 2 spatial dimensions (great for understanding!).\n\n\nsource\n\n\n#\n\n\nTimeseriesPrediction.PCAEmbedding\n \n \nType\n.\n\n\nPCAEmbedding\n(\ns\n,\n \nem\n::\nAbstractSpatialEmbedding\n;\n \nkwargs\n...\n)\n \n\u2192\n \nembedding\n\n\n\n\n\n\nA spatio temporal delay coordinates structure with Principal Component Analysis as a means of dimension reduction, \nembedding\n can be used as a functor:\n\n\nembedding\n(\nrvec\n,\n \ns\n,\n \nt\n,\n \n\u03b1\n)\n\n\n\n\n\n\nwhich operates inplace on \nrvec\n and reconstructs vector from spatial time series \ns\n at timestep \nt\n and cartesian index \n\u03b1\n.\n\n\nTo instantiate this \nembedding\n, give the data to be reconstructed \ns\n as well as an instance of \nSpatioTemporalEmbedding\n to \nPCAEmbedding\n.\n\n\nKeyword Arguments\n\n\n\n\npratio = 0.99\n : Ratio of variances that needs to be preserved in low-dimensional PCA-reconstruction.\n\n\nmaxoutdim = 25\n: Upper limit for output dimension. May break \npratio\n criterion.\n\n\nevery_t = 1\n : Speed up computation by only using every n-th point in time.\n\n\nevery_\u03b1 = 1\n : Speed up computation further by only using every n-th point in space (linear indexing).\n\n\n\n\nTo set the output dimension to a certain value \nX\n, pass \npratio=1, maxoutdim=X\n.\n\n\nsource\n\n\nHere is a function that visualizes how the \nlight_cone_embedding\n works in 2 spatial dimensions:\n\n\nusing\n \nPyPlot\n,\n \nTimeseriesPrediction\n\n\nusing\n \nLinearAlgebra\n:\n \nnorm\n\n\n\nfunction\n \nexplain_light_cone\n(;\n\u03b3\n \n=\n \n2\n,\n \n\u03c4\n \n=\n \n2\n,\n \nr\n \n=\n \n1\n,\n \nc\n \n=\n \n1\n)\n\n\n    \nmaxr\n \n=\n \nD\n*\n\u03c4\n*\nc\n \n+\n \nr0\n\n\n    \nfigure\n()\n\n    \nxticks\n(\n-\nmaxr\n:\nmaxr\n)\n\n    \nyticks\n(\n-\nmaxr\n:\nmaxr\n)\n\n\n    \nfor\n \ni\n \nin\n \n\u03b3\n:-\n1\n:\n0\n\n        \nr\n \n=\n \ni\n*\n\u03c4\n*\nc\n \n+\n \nr\n\n        \npoints\n \n=\n \nTimeseriesPrediction\n.\nindices_within_sphere\n(\nr\n,\n \n2\n)\n\n        \nradius\n \n=\n \nmaximum\n(\nnorm\n(\nTuple\n(\np\n))\n \nfor\n \np\n \nin\n \npoints\n)\n\n\n        \nif\n \nr\n \n!=\n \n0\n\n            \nx\n \n=\n \nr\n*\ncos\n.\n(\nrange\n(\n0\n,\n \nstop\n \n=\n \n2\n\u03c0\n,\n \nlength\n \n=\n \n100\n))\n\n            \ny\n \n=\n \nr\n*\nsin\n.\n(\nrange\n(\n0\n,\n \nstop\n \n=\n \n2\n\u03c0\n,\n \nlength\n \n=\n \n100\n))\n\n            \nplot\n(\nx\n,\ny\n,\n \nc\n \n=\n \nC\n$i\n)\n\n        \nend\n\n\n        \nx\n \n=\n \nmap\n(\nxy\n \n-\n \nxy\n[\n1\n],\n \npoints\n)\n\n        \ny\n \n=\n \nmap\n(\nxy\n \n-\n \nxy\n[\n2\n],\n \npoints\n)\n\n        \nscatter\n(\nx\n,\ny\n,\n \nc\n \n=\n \nC\n$i\n,\n \ns\n=\n100\n,\n \nzorder\n \n=\n \n3\n,\n \nlabel\n \n=\n \nwithin \n\\$\nr = r + \n$i\n \n\\\\\ntau c\n\\$\n)\n\n\n    \nend\n\n    \ntitle\n(\n\u03b3 = \n$\u03b3\n, \u03c4 = \n$\u03c4\n, r = \n$r\n, c = \n$c\n)\n\n    \nPyPlot\n.\ngrid\n(\nzorder\n \n=\n \n-\n1\n)\n\n    \nlegend\n(\nloc\n \n=\n \nupper right\n)\n\n    \nxlabel\n(\nx\n)\n\n    \nylabel\n(\ny\n)\n\n    \nPyPlot\n.\naxis\n(\nequal\n)\n\n    \ntight_layout\n()\n\n\nend\n\n\n\n\n\n\n\n\nBoundary conditions\n\n\n#\n\n\nTimeseriesPrediction.ConstantBoundary\n \n \nType\n.\n\n\nConstantBoundary\n(\nb\n)\n \n:\n \nAbstractBoundaryCondition\n\n\n\n\n\n\nConstant boundary condition type. Enforces constant boundary conditions when passed to \nSpatioTemporalEmbedding\n by filling missing out-of-bounds values in the reconstruction with parameter \nb\n.\n\n\nsource\n\n\n#\n\n\nTimeseriesPrediction.PeriodicBoundary\n \n \nType\n.\n\n\nPeriodicBoundary\n \n:\n \nAbstractBoundaryCondition\n\n\n\n\n\n\nPeriodic boundary condition struct. Enforces periodic boundary conditions when passed to \nSpatioTemporalEmbedding\n in the reconstruction.\n\n\nsource\n\n\n\n\nPrediction functions\n\n\n#\n\n\nTimeseriesPrediction.temporalprediction\n \n \nFunction\n.\n\n\ntemporalprediction\n(\nU\n,\n \nem\n::\nAbstractSpatialEmbedding\n,\n \ntsteps\n;\n \nkwargs\n...\n)\n\n\n\n\n\n\nPerform a spatio-temporal time series prediction for \ntsteps\n iterations, using local weighted modeling [1] give a time series of the form \nU::AbstractVector{\n:AbstractArray{T, \u03a6}}\n.\n\n\nThe returned data always contains the final state of \nU\n as starting point (total returned length is \ntsteps+1\n). The reconstruction process is defined by \nem\n. For available methods and interfaces see \nAbstractSpatialEmbedding\n.\n\n\nKeyword Arguments\n\n\n\n\nttype = KDTree\n : Type/Constructor of tree structure. So far only tested with \nKDTree\n.\n\n\nmethod = AverageLocalModel(\u03c9_safe)\n : Subtype of \nAbstractLocalModel\n.\n\n\nntype = FixedMassNeighborhood(3)\n : Subtype of \nAbstractNeighborhood\n.\n\n\ninitial_ts = U\n : Initial states for prediction (same type as \nU\n). Must have at least as many states as the maximum delay time used. Defaults to the training set \nU\n.\n\n\nprogress = true\n : To print progress done.\n\n\n\n\nDescription\n\n\nThis method works similarly to \nlocalmodel_tsp\n, by expanding the concept of delay embedding to spatially extended systems. Instead of reconstructing complete states of the system, local states are used. See \nAbstractSpatialEmbedding\n for details on the embedding. Predictions are then performed frame by frame and point py point. Once all values for a new frame are found, the frame is added to the end of the timeseries and used to generate new prediction queries for the next time step.\n\n\nPerformance Notes\n\n\nBe careful when choosing embedding parameters as memory usage and computation time depend strongly on the resulting embedding dimension.\n\n\nReferences\n\n\n[1] : U. Parlitz \n C. Merkwirth, \nPhys. Rev. Lett. \n84\n, pp 1890 (2000)\n\n\nsource\n\n\n#\n\n\nTimeseriesPrediction.crossprediction\n \n \nFunction\n.\n\n\ncrossprediction\n(\nsource_train\n,\n \ntarget_train\n,\n \nsource_pred\n,\n\n                \nem\n::\nAbstractSpatialEmbedding\n;\n \nkwargs\n...\n)\n\n\n\n\n\n\nPerform a spatio-temporal timeseries cross-prediction for \ntarget\n from \nsource\n, using local weighted modeling [1]. This can be used for example when there are coupled spatial fields and one is used to predict the other. It is assumed that \nsource_train\n, \ntarget_train\n, \nsource_pred\n are all of the same type, \nAbstractVector{\n:AbstractArray{T, \u03a6}}\n.\n\n\nThe spatio temporal delay embedding process is defined by \nem\n. See \nAbstractSpatialEmbedding\n for available methods and interfaces.\n\n\nKeyword Arguments\n\n\n\n\nttype = KDTree\n : Type/Constructor of tree structure. So far only tested with \nKDTree\n.\n\n\nmethod = AverageLocalModel(\u03c9_safe)\n : Subtype of \nAbstractLocalModel\n.\n\n\nntype = FixedMassNeighborhood(3)\n : Subtype of \nAbstractNeighborhood\n.\n\n\nprogress = true\n : To print progress done.\n\n\n\n\nDescription\n\n\nThe reconstructed state of \nsource_train[t][i,j,...]\n is associated with the output value \ntarget_train[t][i,j,...]\n. This establishes a \"connection\" between \ntarget\n and \nsource\n. Taking a reconstructed state of \nsource_pred\n as query point, the function finds its neighbors in the reconstructed space of \nsource_train\n using neighborhood \nntype\n. Then, the neighbor \nindices\n are used to make a prediction for the corresponding value of the \ntarget\n, using the established \"connection\" between fields.\n\n\nAdditional Interfaces\n\n\nTo save computation time in the case of repeated predictions with the same training set and embedding parameters we provide an additional interface that allows the user to provide an existing reconstruction and tree structure.\n\n\nR\n \n=\n \nreconstruct\n(\ntrain_in\n,\n \nem\n)\n\n\ntree\n \n=\n \nttype\n(\nR\n)\n\n\nparams\n \n=\n \nPredictionParams\n(\nem\n,\n \nmethod\n,\n \nntype\n,\n \nttype\n)\n\n\nsol\n \n=\n \ncrossprediction\n(\nparams\n,\n \ntrain_out\n,\n \npred_in\n,\n \nR\n,\n \ntree\n;\n \nprogress\n=\ntrue\n)\n\n\n\n\n\n\nwhere \nparams\n is an internal container with all relevant parameters.\n\n\nPerformance Notes\n\n\nBe careful when choosing embedding parameters as memory usage and computation time depend strongly on the resulting embedding dimension.\n\n\nReferences\n\n\n[1] : U. Parlitz \n C. Merkwirth, \nPhys. Rev. Lett. \n84\n, pp 1890 (2000)\n\n\nsource", 
            "title": "Spatio-Temporal Prediction"
        }, 
        {
            "location": "/spatiotemporal/#spatiotemporal-timeseries-prediction", 
            "text": "An application and extension of  local modeling  to spatiotemporal timeseries.   Examples  Several example scripts can be found in  TimeseriesPrediction/examples . These examples are run in the  examples  page.", 
            "title": "Spatiotemporal Timeseries Prediction"
        }, 
        {
            "location": "/spatiotemporal/#spatio-temporal-embeddings", 
            "text": "some info here.  #  DelayEmbeddings.reconstruct     Function .  reconstruct ( s :: AbstractArray { : AbstractArray { T , \u03a6 }},   em )   Reconstruct the spatial timeseries  s  represented by a  Vector  of  AbstractArray  states using the embedding struct  em  of type  AbstractSpatialEmbedding .  Returns the reconstruction in the form of a  Dataset  (from  DelayEmbeddings ) where each row is a reconstructed state and they are ordered first through linear indexing into each state and then incrementing in time.  source  #  TimeseriesPrediction.AbstractSpatialEmbedding     Type .  AbstractSpatialEmbedding   :   AbstractEmbedding   Super-type of spatiotemporal embedding methods. Valid subtypes:   SpatioTemporalEmbedding  PCAEmbedding   source  #  TimeseriesPrediction.SpatioTemporalEmbedding     Type .  SpatioTemporalEmbedding { \u03a6 , BC , X }   \u2192   embedding   A spatio temporal delay coordinates structure to be used as a functor. Applies to data of  \u03a6  spatial dimensions and gives an embedding of dimensionality  X .  embedding ( rvec ,   s ,   t ,   \u03b1 )   Operates inplace on  rvec  (of length  X ) and reconstructs vector from spatial timeseries  s  at timestep  t  and cartesian index  \u03b1 . Note that there are no bounds checks for  t .  It is assumed that  s  is a  Vector{ :AbstractArray{T,\u03a6}} .  Constructors  There are some convenience constructors that return intuitive embeddings here:   cubic_shell_embedding  light_cone_embedding   The \"main\" constructor is  SpatioTemporalEmbedding { X } ( \u03c4 ,   \u03b2 ,   bc ,   fsize )   which allows full control over the spatio-temporal embedding.   \u03a7 == length(\u03c4) == length(\u03b2)  : dimensionality of resulting reconstructed space.  \u03c4::Vector{Int}  = Vector of temporal delays  for each entry  of the reconstructed space (sorted in ascending order).  \u03b2::Vector{CartesianIndex{\u03a6}}  = vector of  relative  indices of spatial delays  for each entry  of the reconstructed space.  bc::BC  : boundary condition.  fsize::NTuple{\u03a6, Int}  : Size of each state in the timeseries.   For example, if you want to have spatial neighbors [0, \u00b11] for time delays \u03c4 = 2, 4, then  \u03c4   =   [ 2 , 2 , 2 , 4 , 4 , 4 ]  \u03b2   =   CartesianIndex .([ 1 ,   0 ,   - 1 ,   1 ,   0 ,   - 1 ])   source  #  TimeseriesPrediction.cubic_shell_embedding     Function .  cubic_shell_embedding ( s ,   \u03b3 ,   \u03c4 ,   B ,   k ,   bc = PeriodicBoundary ())   \u2192   embedding   Create a  SpatioTemporalEmbedding  instance that includes spatial neighbors in hypercubic  shells . The embedding is to be used with data from  s .  Description  Points are participating in the embedding by forming hypercubic shells around the current point. The total shells formed are  B . The points on the shells have spatial distance  k \u2265 1  (distance in indices, like a cityblock metric).  k = 1  means that all points of the shell participate. The points of the hypercubic grid can be separated by  k \u2265 1  points apart (i.e. dropping  k-1  in-between points). In short, in each spatial dimension of the system the cartesian offset indices are  -B*k : k : k*B .  \u03b3  is the number of temporal steps in the past to be included in the embedding, where each step in the past has additional delay time  \u03c4::Int .  \u03b3=0  corresponds to using only the present. Notice that  all  embedded time frames have the same spatial structure, in contrast to  light_cone_embedding .  As an example, consider one of the  \u03b3  embedded frames (all are the same) of a system with 2 spatial dimensions ( \u25a1  = current point, (included  by definition  in the embedding),  n  = included points in the embedding coming from  n -th shell,  .  = points not included in the embedding)         B   =   2 ,    k   =   1          |          B   =   1 ,    k   =   2          |          B   =   2 ,    k   =   2 \n                            |                               |  .    .    .    .    .    .    .    .    .    |    .    .    .    .    .    .    .    .    .    |    2    .    2    .    2    .    2    .    2  .    .    .    .    .    .    .    .    .    |    .    .    .    .    .    .    .    .    .    |    .    .    .    .    .    .    .    .    .  .    .    2    2    2    2    2    .    .    |    .    .    1    .    1    .    1    .    .    |    2    .    1    .    1    .    1    .    2  .    .    2    1    1    1    2    .    .    |    .    .    .    .    .    .    .    .    .    |    .    .    .    .    .    .    .    .    .  .    .    2    1    \u25a1    1    2    .    .    |    .    .    1    .    \u25a1    .    1    .    .    |    2    .    1    .    \u25a1    .    1    .    2  .    .    2    1    1    1    2    .    .    |    .    .    .    .    .    .    .    .    .    |    .    .    .    .    .    .    .    .    .  .    .    2    2    2    2    2    .    .    |    .    .    1    .    1    .    1    .    .    |    2    .    1    .    1    .    1    .    2  .    .    .    .    .    .    .    .    .    |    .    .    .    .    .    .    .    .    .    |    .    .    .    .    .    .    .    .    .  .    .    .    .    .    .    .    .    .    |    .    .    .    .    .    .    .    .    .    |    2    .    2    .    2    .    2    .    2   source  #  TimeseriesPrediction.light_cone_embedding     Function .  light_cone_embedding ( s ,   \u03b3 ,   \u03c4 ,   r0 ,   c ,   bc = PeriodicBoundary ())   \u2192   embedding   Create a  SpatioTemporalEmbedding  instance that includes spatial and temporal neighbors of a point based on the notion of a  light cone .  The embedding is to be used with data from  s .  Description  Information does not travel instantly but with some finite speed  c \u2265 0.0 . This constructor creates a cone-like embedding including all points in space and time, whose value can influence a prediction based on the information speed  c .  \u03b3  is the number of temporal steps in the past to be included in the embedding, where each step in the past has additional delay time  \u03c4::Int .  \u03b3=0  corresponds to using only the present.  r0  is the initial radius at the top of the cone, i.e. the radius of influence at the present.  bc  is the boundary condition.  The radius of the light cone evolves as:  r_i = i*\u03c4*c + r0  for each step  i \u2208 0:\u03b3 .  As an example, in a one-dimensional system with  \u03b3 = 1, \u03c4 = 2, r0 = 1 , the embedding looks like ( \u25a1  = current point (included  by definition  in the embedding),  o  point to be predicted using  temporalprediction ,  x  = points included in the embedding,  .  = points not included in the embedding)  time    |   c   =   1 . 0                 |   c   =   2 . 0                 |   c   =   0 . 0  n   +   1   |   .......... o ..........   |   .......... o ..........   |   .......... o ..........  n       |   ......... x \u25a1 x .........   |   ......... x \u25a1 x .........   |   ......... x \u25a1 x .........  n   -   1   |   .....................   |   .....................   |   .....................  n   -   \u03c4   |   ....... xxxxxxx .......   |   ..... xxxxxxxxxx ......   |   ......... xxx .........   Besides this example, in the official documentation we show a function  explain_light_cone  which produces a plot of the light cone for 2 spatial dimensions (great for understanding!).  source  #  TimeseriesPrediction.PCAEmbedding     Type .  PCAEmbedding ( s ,   em :: AbstractSpatialEmbedding ;   kwargs ... )   \u2192   embedding   A spatio temporal delay coordinates structure with Principal Component Analysis as a means of dimension reduction,  embedding  can be used as a functor:  embedding ( rvec ,   s ,   t ,   \u03b1 )   which operates inplace on  rvec  and reconstructs vector from spatial time series  s  at timestep  t  and cartesian index  \u03b1 .  To instantiate this  embedding , give the data to be reconstructed  s  as well as an instance of  SpatioTemporalEmbedding  to  PCAEmbedding .  Keyword Arguments   pratio = 0.99  : Ratio of variances that needs to be preserved in low-dimensional PCA-reconstruction.  maxoutdim = 25 : Upper limit for output dimension. May break  pratio  criterion.  every_t = 1  : Speed up computation by only using every n-th point in time.  every_\u03b1 = 1  : Speed up computation further by only using every n-th point in space (linear indexing).   To set the output dimension to a certain value  X , pass  pratio=1, maxoutdim=X .  source  Here is a function that visualizes how the  light_cone_embedding  works in 2 spatial dimensions:  using   PyPlot ,   TimeseriesPrediction  using   LinearAlgebra :   norm  function   explain_light_cone (; \u03b3   =   2 ,   \u03c4   =   2 ,   r   =   1 ,   c   =   1 ) \n\n     maxr   =   D * \u03c4 * c   +   r0 \n\n     figure () \n     xticks ( - maxr : maxr ) \n     yticks ( - maxr : maxr ) \n\n     for   i   in   \u03b3 :- 1 : 0 \n         r   =   i * \u03c4 * c   +   r \n         points   =   TimeseriesPrediction . indices_within_sphere ( r ,   2 ) \n         radius   =   maximum ( norm ( Tuple ( p ))   for   p   in   points ) \n\n         if   r   !=   0 \n             x   =   r * cos . ( range ( 0 ,   stop   =   2 \u03c0 ,   length   =   100 )) \n             y   =   r * sin . ( range ( 0 ,   stop   =   2 \u03c0 ,   length   =   100 )) \n             plot ( x , y ,   c   =   C $i ) \n         end \n\n         x   =   map ( xy   -   xy [ 1 ],   points ) \n         y   =   map ( xy   -   xy [ 2 ],   points ) \n         scatter ( x , y ,   c   =   C $i ,   s = 100 ,   zorder   =   3 ,   label   =   within  \\$ r = r +  $i   \\\\ tau c \\$ ) \n\n     end \n     title ( \u03b3 =  $\u03b3 , \u03c4 =  $\u03c4 , r =  $r , c =  $c ) \n     PyPlot . grid ( zorder   =   - 1 ) \n     legend ( loc   =   upper right ) \n     xlabel ( x ) \n     ylabel ( y ) \n     PyPlot . axis ( equal ) \n     tight_layout ()  end    Boundary conditions  #  TimeseriesPrediction.ConstantBoundary     Type .  ConstantBoundary ( b )   :   AbstractBoundaryCondition   Constant boundary condition type. Enforces constant boundary conditions when passed to  SpatioTemporalEmbedding  by filling missing out-of-bounds values in the reconstruction with parameter  b .  source  #  TimeseriesPrediction.PeriodicBoundary     Type .  PeriodicBoundary   :   AbstractBoundaryCondition   Periodic boundary condition struct. Enforces periodic boundary conditions when passed to  SpatioTemporalEmbedding  in the reconstruction.  source", 
            "title": "Spatio-Temporal Embeddings"
        }, 
        {
            "location": "/spatiotemporal/#prediction-functions", 
            "text": "#  TimeseriesPrediction.temporalprediction     Function .  temporalprediction ( U ,   em :: AbstractSpatialEmbedding ,   tsteps ;   kwargs ... )   Perform a spatio-temporal time series prediction for  tsteps  iterations, using local weighted modeling [1] give a time series of the form  U::AbstractVector{ :AbstractArray{T, \u03a6}} .  The returned data always contains the final state of  U  as starting point (total returned length is  tsteps+1 ). The reconstruction process is defined by  em . For available methods and interfaces see  AbstractSpatialEmbedding .  Keyword Arguments   ttype = KDTree  : Type/Constructor of tree structure. So far only tested with  KDTree .  method = AverageLocalModel(\u03c9_safe)  : Subtype of  AbstractLocalModel .  ntype = FixedMassNeighborhood(3)  : Subtype of  AbstractNeighborhood .  initial_ts = U  : Initial states for prediction (same type as  U ). Must have at least as many states as the maximum delay time used. Defaults to the training set  U .  progress = true  : To print progress done.   Description  This method works similarly to  localmodel_tsp , by expanding the concept of delay embedding to spatially extended systems. Instead of reconstructing complete states of the system, local states are used. See  AbstractSpatialEmbedding  for details on the embedding. Predictions are then performed frame by frame and point py point. Once all values for a new frame are found, the frame is added to the end of the timeseries and used to generate new prediction queries for the next time step.  Performance Notes  Be careful when choosing embedding parameters as memory usage and computation time depend strongly on the resulting embedding dimension.  References  [1] : U. Parlitz   C. Merkwirth,  Phys. Rev. Lett.  84 , pp 1890 (2000)  source  #  TimeseriesPrediction.crossprediction     Function .  crossprediction ( source_train ,   target_train ,   source_pred , \n                 em :: AbstractSpatialEmbedding ;   kwargs ... )   Perform a spatio-temporal timeseries cross-prediction for  target  from  source , using local weighted modeling [1]. This can be used for example when there are coupled spatial fields and one is used to predict the other. It is assumed that  source_train ,  target_train ,  source_pred  are all of the same type,  AbstractVector{ :AbstractArray{T, \u03a6}} .  The spatio temporal delay embedding process is defined by  em . See  AbstractSpatialEmbedding  for available methods and interfaces.  Keyword Arguments   ttype = KDTree  : Type/Constructor of tree structure. So far only tested with  KDTree .  method = AverageLocalModel(\u03c9_safe)  : Subtype of  AbstractLocalModel .  ntype = FixedMassNeighborhood(3)  : Subtype of  AbstractNeighborhood .  progress = true  : To print progress done.   Description  The reconstructed state of  source_train[t][i,j,...]  is associated with the output value  target_train[t][i,j,...] . This establishes a \"connection\" between  target  and  source . Taking a reconstructed state of  source_pred  as query point, the function finds its neighbors in the reconstructed space of  source_train  using neighborhood  ntype . Then, the neighbor  indices  are used to make a prediction for the corresponding value of the  target , using the established \"connection\" between fields.  Additional Interfaces  To save computation time in the case of repeated predictions with the same training set and embedding parameters we provide an additional interface that allows the user to provide an existing reconstruction and tree structure.  R   =   reconstruct ( train_in ,   em )  tree   =   ttype ( R )  params   =   PredictionParams ( em ,   method ,   ntype ,   ttype )  sol   =   crossprediction ( params ,   train_out ,   pred_in ,   R ,   tree ;   progress = true )   where  params  is an internal container with all relevant parameters.  Performance Notes  Be careful when choosing embedding parameters as memory usage and computation time depend strongly on the resulting embedding dimension.  References  [1] : U. Parlitz   C. Merkwirth,  Phys. Rev. Lett.  84 , pp 1890 (2000)  source", 
            "title": "Prediction functions"
        }, 
        {
            "location": "/stexamples/", 
            "text": "Spatio-Temporal Prediction Examples\n\n\nIn this page we are simply running files from the \nexamples\n folder of the \nTimeseriesPrediction\n package.\n\n\nThis is how you can (programmatically) find this folder:\n\n\nusing\n \nTimeseriesPrediction\n\n\nexdir\n \n=\n \ndirname\n(\ndirname\n(\npathof\n(\nTimeseriesPrediction\n)))\n*\n/examples\n\n\n\n\n\n\n\n\nTemporal Prediction: Kuramoto-Sivashinsky\n\n\n(this requires \nFFTW\n to be installed)\n\n\nThis example predicts the temporal evolution of a one-dimensional field U, along with a time vector T, which has to be represented as vectors of vectors. Where the field comes from does not matter, but to make the example runnable we load one of the test systems of \nTimeseriesPrediction\n.\n\n\nIn this example we use the solution of Kuramoto Sivashinsky equation.\n\n\nImportantly, the results are compared with the \"real\" evolution of the system.\n\n\nIn the plots, the x axis is space and y axis is time.\n\n\n\n\nProduce field U (Kuramoto Sivashinsky)\n\n\nusing\n \nPyPlot\n\n\nusing\n \nTimeseriesPrediction\n\n\n\ntestdir\n \n=\n \ndirname\n(\ndirname\n(\npathof\n(\nTimeseriesPrediction\n)))\n*\n/test\n\n\n@assert\n \nisdir\n(\ntestdir\n)\n\n\ninclude\n(\ntestdir\n*\n/ks_solver.jl\n)\n\n\n\nNtrain\n \n=\n \n10000\n\n\np\n \n=\n \n100\n\n\nN\n \n=\n \nNtrain\n \n+\n \np\n\n\n\nU\n,\n \nT\n \n=\n \nKuramotoSivashinsky\n(\n64\n,\n \n22\n,\n \nN\u00f74\n,\n \n0.25\n)\n\n\nsummary\n(\nU\n)\n\n\n\n\n\n\n10101-element Array{Array{Float64,1},1}\n\n\n\n\n\n\n\n\nTemporal prediction of field U\n\n\nQ\n \n=\n \nlength\n(\nU\n[\n1\n])\n \n# spatial length\n\n\npool\n \n=\n \nU\n[\n1\n:\nNtrain\n]\n\n\ntest\n \n=\n \nU\n[\nNtrain\n:\nN\n]\n\n\n\n\u03b3\n \n=\n \n10\n\n\n\u03c4\n \n=\n \n1\n\n\nB\n \n=\n \n10\n\n\nk\n \n=\n \n1\n\n\nntype\n \n=\n \nFixedMassNeighborhood\n(\n4\n)\n\n\nmethod\n \n=\n \nAverageLocalModel\n()\n\n\n\nem\n \n=\n \ncubic_shell_embedding\n(\npool\n,\n \n\u03b3\n,\n\u03c4\n,\nB\n,\nk\n,\nPeriodicBoundary\n())\n\n\npcaem\n=\n \nPCAEmbedding\n(\npool\n,\nem\n)\n\n\n\n@time\n \npred\n \n=\n \ntemporalprediction\n(\npool\n,\npcaem\n,\n \np\n;\nntype\n=\nntype\n,\n \nmethod\n=\nmethod\n,\n \nprogress\n \n=\n \nfalse\n)\n\n\n\nerr\n \n=\n \n[\nabs\n.\n(\ntest\n[\ni\n]\n-\npred\n[\ni\n])\n \nfor\n \ni\n=\n1\n:\np\n+\n1\n]\n\n\nprintln\n(\nMaximum error: \n,\n \nmaximum\n(\nmaximum\n(\ne\n)\n \nfor\n \ne\n \nin\n \nerr\n))\n\n\n\n\n\n\n  \n3\n.\n203749\n \nseconds\n \n(\n4\n.\n12\n \nM\n \nallocations\n:\n \n278\n.\n923\n \nMiB\n,\n \n12\n.\n76\n%\n \ngc\n \ntime\n)\n\n\nMaximum\n \nerror\n:\n \n7\n.\n489722699875914\n\n\n\n\n\n\n\n\nPlot the result\n\n\nDeduce field extremal values\n\n\nvmax\n \n=\n \nmax\n(\nmaximum\n(\nmaximum\n(\ns\n)\n \nfor\n \ns\n \nin\n \ntest\n),\n\n           \nmaximum\n(\nmaximum\n(\ns\n)\n \nfor\n \ns\n \nin\n \npred\n))\n\n\nvmin\n \n=\n \nmin\n(\nminimum\n(\nminimum\n(\ns\n)\n \nfor\n \ns\n \nin\n \ntest\n),\n\n           \nminimum\n(\nminimum\n(\ns\n)\n \nfor\n \ns\n \nin\n \npred\n))\n\n\n\n\n\n\n-\n5\n.\n275917990623304\n\n\n\n\n\n\nTransform data for imshow\n\n\nptest\n \n=\n \ncat\n(\ntest\n...\n,\n \ndims\n \n=\n \n2\n)\n\n\nppred\n \n=\n \ncat\n(\npred\n...\n,\n \ndims\n \n=\n \n2\n)\n\n\nperr\n \n=\n \ncat\n(\nerr\n...\n,\n \ndims\n \n=\n \n2\n)\n\n\n\n\n\n\n64\n\u00d7\n101\n \nArray\n{\nFloat64\n,\n2\n}\n:\n\n \n0\n.\n0\n  \n0\n.\n117557\n     \n0\n.\n093332\n    \n0\n.\n0995133\n   \n\u2026\n  \n0\n.\n176435\n  \n0\n.\n428045\n  \n1\n.\n12381\n \n \n0\n.\n0\n  \n0\n.\n0844138\n    \n0\n.\n0624008\n   \n0\n.\n0627831\n      \n1\n.\n03725\n   \n0\n.\n634373\n  \n0\n.\n149066\n\n \n0\n.\n0\n  \n0\n.\n0487361\n    \n0\n.\n0268789\n   \n0\n.\n0249753\n      \n1\n.\n51933\n   \n1\n.\n35378\n   \n1\n.\n12772\n \n \n0\n.\n0\n  \n0\n.\n0430553\n    \n0\n.\n00531474\n  \n0\n.\n00402415\n     \n1\n.\n65941\n   \n1\n.\n72697\n   \n1\n.\n76369\n \n \n0\n.\n0\n  \n0\n.\n0550993\n    \n0\n.\n00717697\n  \n0\n.\n00488774\n     \n1\n.\n54245\n   \n1\n.\n80927\n   \n2\n.\n07716\n \n \n0\n.\n0\n  \n0\n.\n0513383\n    \n0\n.\n0131881\n   \n0\n.\n00198239\n  \n\u2026\n  \n1\n.\n27599\n   \n1\n.\n69305\n   \n2\n.\n13234\n \n \n0\n.\n0\n  \n0\n.\n0394528\n    \n0\n.\n0126422\n   \n0\n.\n0254385\n      \n0\n.\n977606\n  \n1\n.\n4845\n    \n2\n.\n02576\n \n \n0\n.\n0\n  \n0\n.\n0222963\n    \n0\n.\n0454558\n   \n0\n.\n0583722\n      \n0\n.\n749201\n  \n1\n.\n27235\n   \n1\n.\n84884\n \n \n0\n.\n0\n  \n0\n.\n0113543\n    \n0\n.\n0875975\n   \n0\n.\n102984\n       \n0\n.\n625136\n  \n1\n.\n10491\n   \n1\n.\n6342\n  \n \n0\n.\n0\n  \n0\n.\n000283291\n  \n0\n.\n121417\n    \n0\n.\n137955\n       \n0\n.\n64153\n   \n1\n.\n04758\n   \n1\n.\n47385\n \n \n\u22ee\n                                         \n\u22f1\n                      \n\u22ee\n       \n \n0\n.\n0\n  \n0\n.\n0806688\n    \n0\n.\n0717503\n   \n0\n.\n0555449\n   \n\u2026\n  \n3\n.\n34076\n   \n2\n.\n8054\n    \n2\n.\n20618\n \n \n0\n.\n0\n  \n0\n.\n103009\n     \n0\n.\n0765522\n   \n0\n.\n0773288\n      \n4\n.\n80043\n   \n4\n.\n36622\n   \n3\n.\n83916\n \n \n0\n.\n0\n  \n0\n.\n0407499\n    \n0\n.\n0130141\n   \n0\n.\n0274053\n      \n5\n.\n84244\n   \n5\n.\n59799\n   \n5\n.\n24194\n \n \n0\n.\n0\n  \n0\n.\n00136207\n   \n0\n.\n0219034\n   \n0\n.\n084694\n       \n6\n.\n28648\n   \n6\n.\n2951\n    \n6\n.\n18903\n \n \n0\n.\n0\n  \n0\n.\n0325506\n    \n0\n.\n0315577\n   \n0\n.\n0891074\n      \n6\n.\n06503\n   \n6\n.\n34578\n   \n6\n.\n52844\n \n \n0\n.\n0\n  \n0\n.\n0460529\n    \n0\n.\n0990307\n   \n0\n.\n0424581\n   \n\u2026\n  \n5\n.\n23427\n   \n5\n.\n75757\n   \n6\n.\n21841\n \n \n0\n.\n0\n  \n0\n.\n0623423\n    \n0\n.\n114259\n    \n0\n.\n138285\n       \n3\n.\n96122\n   \n4\n.\n65298\n   \n5\n.\n33638\n \n \n0\n.\n0\n  \n0\n.\n0751481\n    \n0\n.\n135083\n    \n0\n.\n139311\n       \n2\n.\n47919\n   \n3\n.\n24312\n   \n4\n.\n04871\n \n \n0\n.\n0\n  \n0\n.\n100207\n     \n0\n.\n134398\n    \n0\n.\n130669\n       \n1\n.\n03333\n   \n1\n.\n76527\n   \n2\n.\n57602\n \n\n\n\n\n\nplot plot plot\n\n\nfig\n \n=\n \nfigure\n(\nfigsize\n=\n(\n8\n,\n8\n))\n\n\nax1\n \n=\n \nsubplot2grid\n((\n3\n,\n1\n),\n \n(\n0\n,\n0\n))\n\n\nax2\n \n=\n \nsubplot2grid\n((\n3\n,\n1\n),\n \n(\n1\n,\n0\n))\n\n\nax3\n \n=\n \nsubplot2grid\n((\n3\n,\n1\n),\n \n(\n2\n,\n0\n));\n\n\n\nim1\n \n=\n \nax1\n[\n:\nimshow\n](\nppred\n,\n \ncmap\n=\nviridis\n,\n \nvmin\n \n=\n \nvmin\n,\n \nvmax\n \n=\n \nvmax\n,\n\n\naspect\n \n=\n \nauto\n,\n \nextent\n \n=\n \n(\nT\n[\nNtrain\n],\n \nT\n[\nN\n],\n \n1\n,\n \nQ\n))\n\n\nim2\n \n=\n \nax2\n[\n:\nimshow\n](\nptest\n,\n \ncmap\n=\nviridis\n,\n \nvmin\n \n=\n \nvmin\n,\n \nvmax\n \n=\n \nvmax\n,\n\n\naspect\n \n=\n \nauto\n,\n \nextent\n \n=\n \n(\nT\n[\nNtrain\n],\n \nT\n[\nN\n],\n \n1\n,\n \nQ\n))\n\n\nim3\n \n=\n \nax3\n[\n:\nimshow\n](\nperr\n,\n \ncmap\n=\ninferno\n,\n \nvmin\n \n=\n \n0\n,\n \nvmax\n \n=\n \nvmax\n-\nvmin\n,\n\n\naspect\n \n=\n \nauto\n,\n \nextent\n \n=\n \n(\nT\n[\nNtrain\n],\n \nT\n[\nN\n],\n \n1\n,\n \nQ\n))\n\n\n\nfor\n \n(\nj\n,\n \n(\nim\n,\n \nax\n))\n \nin\n \nenumerate\n(\nzip\n([\nim1\n,\nim2\n,\nim3\n],\n \n[\nax1\n,\nax2\n,\nax3\n]))\n\n    \ncolorbar\n(\nim\n,\n \nax\n \n=\n \nax\n,\n \nfraction\n=\n0.04\n,\n \npad\n=\n0.01\n)\n# format=\n%.1f\n)\n\n    \nif\n \nj\n \n \n3\n\n        \nax\n[\n:\nset_xticklabels\n]([])\n\n    \nend\n\n\nend\n\n\nax1\n[\n:\nset_title\n](\nPrediction\n)\n\n\nax2\n[\n:\nset_title\n](\nReal evolution\n)\n\n\nax3\n[\n:\nset_title\n](\nAbsolute error\n)\n\n\n\nax2\n[\n:\nset_ylabel\n](\nspace\n)\n\n\nax3\n[\n:\nset_xlabel\n](\ntime\n)\n\n\ntight_layout\n(\nw_pad\n=\n0.1\n,\n \nh_pad\n=\n0.00001\n)\n\n\n\n\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nmake\n.\njl\n:\n28\n\n\n\u2514\n \n@\n \nCore\n \n~/\nbuild\n/\nJuliaDynamics\n/\nTimeseriesPrediction\n.\njl\n/\ndocs\n/\nmake\n.\njl\n:\n28\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nmake\n.\njl\n:\n28\n\n\n\u2514\n \n@\n \nCore\n \n~/\nbuild\n/\nJuliaDynamics\n/\nTimeseriesPrediction\n.\njl\n/\ndocs\n/\nmake\n.\njl\n:\n28\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nmake\n.\njl\n:\n28\n\n\n\u2514\n \n@\n \nCore\n \n~/\nbuild\n/\nJuliaDynamics\n/\nTimeseriesPrediction\n.\njl\n/\ndocs\n/\nmake\n.\njl\n:\n28\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n5\n \n[\ninlined\n]\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n5\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nmake\n.\njl\n:\n28\n\n\n\u2514\n \n@\n \nCore\n \n~/\nbuild\n/\nJuliaDynamics\n/\nTimeseriesPrediction\n.\njl\n/\ndocs\n/\nmake\n.\njl\n:\n28\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nmake\n.\njl\n:\n28\n\n\n\u2514\n \n@\n \nCore\n \n~/\nbuild\n/\nJuliaDynamics\n/\nTimeseriesPrediction\n.\njl\n/\ndocs\n/\nmake\n.\njl\n:\n28\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nmake\n.\njl\n:\n28\n\n\n\u2514\n \n@\n \nCore\n \n~/\nbuild\n/\nJuliaDynamics\n/\nTimeseriesPrediction\n.\njl\n/\ndocs\n/\nmake\n.\njl\n:\n28\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nmake\n.\njl\n:\n28\n\n\n\u2514\n \n@\n \nCore\n \n~/\nbuild\n/\nJuliaDynamics\n/\nTimeseriesPrediction\n.\njl\n/\ndocs\n/\nmake\n.\njl\n:\n28\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nmake\n.\njl\n:\n28\n\n\n\u2514\n \n@\n \nCore\n \n~/\nbuild\n/\nJuliaDynamics\n/\nTimeseriesPrediction\n.\njl\n/\ndocs\n/\nmake\n.\njl\n:\n28\n\n\n\n\n\n\n\n\n\n\nCross Prediction: Barkley Model\n\n\nThis example cross-predicts a field U from a field V. Both fields have to be represented as vectors of matrices. Where the fields come from does not matter, but to make the example runnable we load one of the test systems of TimeseriesPrediction.\n\n\nThis example uses cubic shell embedding and a linear Barkley model.\n\n\nImportantly, the results are compared with the \"real\" evolution of the system.\n\n\n\n\nSimulate a test system\n\n\nusing\n \nPyPlot\n\n\nusing\n \nTimeseriesPrediction\n\n\n\ntestdir\n \n=\n \ndirname\n(\ndirname\n(\npathof\n(\nTimeseriesPrediction\n)))\n*\n/test\n\n\n@assert\n \nisdir\n(\ntestdir\n)\n\n\ninclude\n(\ntestdir\n*\n/system_defs.jl\n)\n\n\n\nTtrain\n \n=\n \n500\n\n\nTtest\n \n=\n \n10\n\n\nT\n \n=\n \nTtrain\n \n+\n \nTtest\n\n\n\nU\n,\n \nV\n \n=\n \nbarkley\n(\nT\n;\ntskip\n=\n100\n,\n \nssize\n=\n(\n50\n,\n50\n))\n\n\nsummary\n(\nU\n)\n\n\n\n\n\n\n510-element Array{Array{Float64,2},1}\n\n\n\n\n\n\n\n\nCross predict field U from field V\n\n\n\u03b3\n \n=\n \n5\n\n\n\u03c4\n \n=\n \n1\n\n\nB\n \n=\n \n1\n\n\nk\n \n=\n \n1\n\n\nbc\n \n=\n \nPeriodicBoundary\n()\n\n\n\nsource_train\n \n=\n \nV\n[\n1\n:\n \nTtrain\n]\n\n\ntarget_train\n \n=\n \nU\n[\n1\n:\n \nTtrain\n]\n\n\nsource_pred\n  \n=\n \nV\n[\nTtrain\n  \n-\n \n\u03b3\n*\n\u03c4\n \n+\n \n1\n:\n  \nT\n]\n\n\ntarget_test\n  \n=\n \nU\n[\nTtrain\n        \n+\n \n1\n:\n  \nT\n]\n\n\n\nem\n \n=\n \ncubic_shell_embedding\n(\nsource_train\n,\n \n\u03b3\n,\n\u03c4\n,\nB\n,\nk\n,\nbc\n)\n\n\npcaem\n \n=\n \nPCAEmbedding\n(\nsource_train\n,\n \nem\n;\n \nmaxoutdim\n=\n5\n)\n \n# PCA speeds things up!\n\n\n\n@time\n \ntarget_pred\n \n=\n \ncrossprediction\n(\nsource_train\n,\n \ntarget_train\n,\n \nsource_pred\n,\n \nem\n;\n\n\nprogress\n \n=\n \nfalse\n)\n\n\n\nerr\n \n=\n \n[\nabs\n.\n(\ntarget_test\n[\ni\n]\n-\ntarget_pred\n[\ni\n])\n \nfor\n \ni\n=\n1\n:\nTtest\n]\n\n\n\nprintln\n(\nMaximum error: \n,\n \nmaximum\n(\nmaximum\n(\ne\n)\n \nfor\n \ne\n \nin\n \nerr\n))\n\n\n\n\n\n\n \n50\n.\n487440\n \nseconds\n \n(\n1\n.\n86\n \nM\n \nallocations\n:\n \n1\n.\n178\n \nGiB\n,\n \n1\n.\n31\n%\n \ngc\n \ntime\n)\n\n\nMaximum\n \nerror\n:\n \n0\n.\n2819220583817802\n\n\n\n\n\n\n\n\nPlot prediction\n\n\nDeduce field extremal values\n\n\nsource_max\n \n=\n \nmaximum\n(\nmaximum\n(\ns\n)\n \nfor\n \ns\n \nin\n \nsource_pred\n)\n\n\ntarget_max\n \n=\n \nmax\n(\nmaximum\n(\nmaximum\n(\ns\n)\n \nfor\n \ns\n \nin\n \ntarget_test\n),\n\n                 \nmaximum\n(\nmaximum\n(\ns\n)\n \nfor\n \ns\n \nin\n \ntarget_pred\n))\n\n\nsource_min\n \n=\n \nminimum\n(\nminimum\n(\ns\n)\n \nfor\n \ns\n \nin\n \nsource_pred\n)\n\n\ntarget_min\n \n=\n \nmin\n(\nminimum\n(\nminimum\n(\ns\n)\n \nfor\n \ns\n \nin\n \ntarget_test\n),\n\n                 \nminimum\n(\nminimum\n(\ns\n)\n \nfor\n \ns\n \nin\n \ntarget_pred\n))\n\n\n\n\n\n\n8\n.\n006923371978363\ne\n-\n5\n\n\n\n\n\n\nPlot various predicted frames (only the last one shown here)\n\n\nfor\n \ni\n \nin\n \n[\n1\n,\n \nlength\n(\nerr\n)\n\u00f7\n2\n,\n \nlength\n(\nerr\n)]\n\n\n    \nfig\n \n=\n \nfigure\n(\nfigsize\n=\n(\n10\n,\n10\n))\n\n    \nax1\n \n=\n \nsubplot2grid\n((\n2\n,\n2\n),\n \n(\n0\n,\n0\n))\n\n    \nax2\n \n=\n \nsubplot2grid\n((\n2\n,\n2\n),\n \n(\n0\n,\n1\n))\n\n    \nax3\n \n=\n \nsubplot2grid\n((\n2\n,\n2\n),\n \n(\n1\n,\n0\n))\n\n    \nax4\n \n=\n \nsubplot2grid\n((\n2\n,\n2\n),\n \n(\n1\n,\n1\n))\n\n    \nim1\n \n=\n \nax1\n[\n:\nimshow\n](\nsource_pred\n[\ni\n],\n \ncmap\n=\nviridis\n,\n \nvmin\n \n=\n \nsource_min\n,\n \nvmax\n \n=\n \nsource_max\n)\n\n    \nim2\n \n=\n \nax2\n[\n:\nimshow\n](\ntarget_test\n[\ni\n],\n \ncmap\n=\ncividis\n,\n \nvmin\n \n=\n \ntarget_min\n,\n \nvmax\n \n=\n \ntarget_max\n)\n\n    \nim3\n \n=\n \nax3\n[\n:\nimshow\n](\ntarget_pred\n[\ni\n],\n \ncmap\n=\ncividis\n,\n \nvmin\n \n=\n \ntarget_min\n,\n \nvmax\n \n=\n \ntarget_max\n)\n\n    \nim4\n \n=\n \nax4\n[\n:\nimshow\n](\nerr\n[\ni\n],\n \ncmap\n=\ninferno\n,\n \nvmin\n \n=\n \n0\n,\n \nvmax\n \n=\n \ntarget_max\n \n-\n \ntarget_min\n)\n\n    \nfor\n \n(\nim\n,\n \nax\n)\n \nin\n \nzip\n([\nim1\n,\nim2\n,\nim3\n,\nim4\n],\n \n[\nax1\n,\nax2\n,\nax3\n,\nax4\n])\n\n        \nax\n[\n:\nget_xaxis\n]()[\n:\nset_ticks\n]([])\n\n        \nax\n[\n:\nget_yaxis\n]()[\n:\nset_ticks\n]([])\n\n        \ncolorbar\n(\nim\n,\n \nax\n \n=\n \nax\n,\n \nfraction\n=\n0.046\n,\n \npad\n=\n0.04\n)\n#, format=\n%.1f\n)\n\n    \nend\n\n    \nax1\n[\n:\nset_title\n](\nSource\n)\n\n    \nax2\n[\n:\nset_title\n](\nTarget Test\n)\n\n    \nax3\n[\n:\nset_title\n](\nTarget Cross-Pred.\n)\n\n    \nax4\n[\n:\nset_title\n](\nabsolute error\n)\n\n    \ntight_layout\n(\nw_pad\n=\n0.6\n,\n \nh_pad\n=\n0.00001\n)\n\n    \nsuptitle\n(\nframe \n$i\n)\n\n\nend\n\n\n\n\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n8\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n8\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n9\n \n[\ninlined\n]\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n9\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n10\n \n[\ninlined\n]\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n10\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n11\n \n[\ninlined\n]\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n11\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n13\n \n[\ninlined\n]\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n13\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n13\n \n[\ninlined\n]\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n13\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n14\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n14\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n14\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n14\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n17\n \n[\ninlined\n]\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n17\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n18\n \n[\ninlined\n]\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n18\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n19\n \n[\ninlined\n]\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n19\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n20\n \n[\ninlined\n]\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n20\n\n\n\n\n\n\n\n\n\n\nTemporal Prediction: Periodic Nonlinear Barkley Model\n\n\nThis example predicts the temporal evolution of a field U, which has to be represented as vectors of matrices. Where the field comes from does not matter, but to make the example runnable we load one of the test systems of TimeseriesPrediction.\n\n\nThis example uses light cone embedding and a nonlinear Barkley model.\n\n\nImportantly, the results are compared with the \"real\" evolution of the system.\n\n\n\n\nSimulate a test system\n\n\nusing\n \nPyPlot\n\n\nusing\n \nTimeseriesPrediction\n\n\n\ntestdir\n \n=\n \ndirname\n(\ndirname\n(\npathof\n(\nTimeseriesPrediction\n)))\n*\n/test\n\n\n@assert\n \nisdir\n(\ntestdir\n)\n\n\ninclude\n(\ntestdir\n*\n/system_defs.jl\n)\n\n\n\nTtrain\n \n=\n \n300\n\n\nTtest\n \n=\n \n5\n\n\nT\n \n=\n \nTtrain\n \n+\n \nTtest\n\n\n\ninit\n \n=\n \n[\n \n0.6241\n    \n0.589685\n  \n0.668221\n   \n0.194882\n    \n0.687645\n\n         \n0.656243\n  \n0.702544\n  \n0.476963\n   \n0.00236098\n  \n0.636111\n\n         \n0.821854\n  \n0.868514\n  \n0.242682\n   \n0.2588\n      \n0.30552\n\n         \n0.580972\n  \n0.355305\n  \n0.0805268\n  \n0.501724\n    \n0.728142\n\n         \n0.297559\n  \n0.708676\n  \n0.583552\n   \n0.65363\n     \n0.555639\n]\n\n\n\nU\n,\n \nV\n \n=\n \nbarkley\n(\nT\n;\n \ntskip\n=\n100\n,\n \nssize\n=\n(\n50\n,\n50\n),\n \ninit\n \n=\n \ninit\n)\n\n\nsummary\n(\nU\n)\n\n\n\n\n\n\n305-element Array{Array{Float64,2},1}\n\n\n\n\n\n\n\n\nTemporal prediction of field U\n\n\n\u03b3\n \n=\n \n2\n\n\n\u03c4\n \n=\n \n1\n\n\nr\n \n=\n \n1\n\n\nc\n \n=\n \n1\n\n\nbc\n \n=\n \nPeriodicBoundary\n()\n\n\n\npool\n \n=\n \nU\n[\n1\n \n:\n \nTtrain\n]\n\n\ntest\n  \n=\n \nU\n[\n \nTtrain\n \n:\n \nT\n]\n\n\n\nem\n \n=\n \nlight_cone_embedding\n(\npool\n,\n \n\u03b3\n,\n\u03c4\n,\nr\n,\nc\n,\nbc\n)\n\n\npcaem\n \n=\n \nPCAEmbedding\n(\npool\n,\n \nem\n;\n \nmaxoutdim\n=\n5\n)\n \n# PCA speeds things up!\n\n\n\n@time\n \npred\n \n=\n \ntemporalprediction\n(\npool\n,\n \nem\n,\n \nTtest\n;\n \nprogress\n \n=\n \nfalse\n)\n\n\n\nerr\n \n=\n \n[\nabs\n.\n(\ntest\n[\ni\n]\n-\npred\n[\ni\n])\n \nfor\n \ni\n=\n1\n:\nTtest\n+\n1\n]\n\n\n\nprintln\n(\nMaximum error: \n,\n \nmaximum\n(\nmaximum\n(\ne\n)\n \nfor\n \ne\n \nin\n \nerr\n))\n\n\n\n\n\n\n \n25\n.\n033708\n \nseconds\n \n(\n1\n.\n72\n \nM\n \nallocations\n:\n \n931\n.\n762\n \nMiB\n,\n \n1\n.\n73\n%\n \ngc\n \ntime\n)\n\n\nMaximum\n \nerror\n:\n \n0\n.\n2934269941090367\n\n\n\n\n\n\n\n\nPlot prediction\n\n\nDeduce field maximum values\n\n\nvmax\n \n=\n \nmax\n(\nmaximum\n(\nmaximum\n(\ns\n)\n \nfor\n \ns\n \nin\n \ntest\n),\n\n           \nmaximum\n(\nmaximum\n(\ns\n)\n \nfor\n \ns\n \nin\n \npred\n))\n\n\nvmin\n \n=\n \nmin\n(\nminimum\n(\nminimum\n(\ns\n)\n \nfor\n \ns\n \nin\n \ntest\n),\n\n           \nminimum\n(\nminimum\n(\ns\n)\n \nfor\n \ns\n \nin\n \npred\n))\n\n\n\n\n\n\n0\n.\n0015249975046802136\n\n\n\n\n\n\nplot plot plot\n\n\nfor\n \ni\n \nin\n \n[\n1\n,\n \nlength\n(\nerr\n)\n\u00f7\n2\n,\n \nlength\n(\nerr\n)]\n\n\n    \nfig\n \n=\n \nfigure\n(\nfigsize\n=\n(\n10\n,\n3\n))\n\n    \nax1\n \n=\n \nsubplot2grid\n((\n1\n,\n3\n),\n \n(\n0\n,\n0\n))\n\n    \nax2\n \n=\n \nsubplot2grid\n((\n1\n,\n3\n),\n \n(\n0\n,\n1\n))\n\n    \nax3\n \n=\n \nsubplot2grid\n((\n1\n,\n3\n),\n \n(\n0\n,\n2\n))\n\n\n    \nim1\n \n=\n \nax1\n[\n:\nimshow\n](\npred\n[\ni\n],\n \ncmap\n=\nviridis\n,\n \nvmin\n \n=\n \nvmin\n,\n \nvmax\n \n=\n \nvmax\n)\n\n    \nim2\n \n=\n \nax2\n[\n:\nimshow\n](\ntest\n[\ni\n],\n \ncmap\n=\nviridis\n,\n \nvmin\n \n=\n \nvmin\n,\n \nvmax\n \n=\n \nvmax\n)\n\n    \nim3\n \n=\n \nax3\n[\n:\nimshow\n](\nerr\n[\ni\n],\n \ncmap\n=\ninferno\n,\n \nvmin\n \n=\n \n0\n,\n \nvmax\n \n=\n \nvmax\n-\nvmin\n)\n\n    \nfor\n \n(\nim\n,\n \nax\n)\n \nin\n \nzip\n([\nim1\n,\nim2\n,\nim3\n],\n \n[\nax1\n,\nax2\n,\nax3\n])\n\n        \nax\n[\n:\nget_xaxis\n]()[\n:\nset_ticks\n]([])\n\n        \nax\n[\n:\nget_yaxis\n]()[\n:\nset_ticks\n]([])\n\n        \ncolorbar\n(\nim\n,\n \nax\n \n=\n \nax\n,\n \nfraction\n=\n0.046\n,\n \npad\n=\n0.04\n)\n#, format=\n%.1f\n)\n\n    \nend\n\n    \nax1\n[\n:\nset_title\n](\nPrediction\n)\n\n    \nax2\n[\n:\nset_title\n](\nReal evolution\n)\n\n    \nax3\n[\n:\nset_title\n](\nAbsolute error\n)\n\n    \nsuptitle\n(\nframe \n$i\n)\n\n    \ntight_layout\n(\nw_pad\n=\n0.6\n,\n \nh_pad\n=\n0.00001\n)\n\n    \nsubplots_adjust\n(\ntop\n=\n0.75\n)\n\n\nend\n\n\n\n\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n8\n \n[\ninlined\n]\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n8\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n9\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n9\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n10\n \n[\ninlined\n]\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n10\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n12\n \n[\ninlined\n]\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n12\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n12\n \n[\ninlined\n]\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n12\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n13\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n13\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n13\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n13\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n16\n \n[\ninlined\n]\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n16\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n17\n \n[\ninlined\n]\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n17\n\n\n\u250c\n \nWarning\n:\n \n`getindex(o::PyObject, s::Symbol)`\n \nis\n \ndeprecated\n \nin\n \nfavor\n \nof\n \ndot\n \noverloading\n \n(\n`getproperty`\n)\n \nso\n \nelements\n \nshould\n \nnow\n \nbe\n \naccessed\n \nas\n \ne\n.\ng\n.\n \n`o.s`\n \ninstead\n \nof\n \n`o[:s]`\n.\n\n\n\u2502\n   \ncaller\n \n=\n \ntop\n-\nlevel\n \nscope\n \nat\n \nnone\n:\n18\n \n[\ninlined\n]\n\n\n\u2514\n \n@\n \nCore\n \n.\n/\nnone\n:\n18\n\n\n\n\n\n\n\n\nThis page was generated using \nLiterate.jl\n.", 
            "title": "Spatio-Temporal Examples"
        }, 
        {
            "location": "/stexamples/#spatio-temporal-prediction-examples", 
            "text": "In this page we are simply running files from the  examples  folder of the  TimeseriesPrediction  package.  This is how you can (programmatically) find this folder:  using   TimeseriesPrediction  exdir   =   dirname ( dirname ( pathof ( TimeseriesPrediction ))) * /examples", 
            "title": "Spatio-Temporal Prediction Examples"
        }, 
        {
            "location": "/stexamples/#temporal-prediction-kuramoto-sivashinsky", 
            "text": "(this requires  FFTW  to be installed)  This example predicts the temporal evolution of a one-dimensional field U, along with a time vector T, which has to be represented as vectors of vectors. Where the field comes from does not matter, but to make the example runnable we load one of the test systems of  TimeseriesPrediction .  In this example we use the solution of Kuramoto Sivashinsky equation.  Importantly, the results are compared with the \"real\" evolution of the system.  In the plots, the x axis is space and y axis is time.", 
            "title": "Temporal Prediction: Kuramoto-Sivashinsky"
        }, 
        {
            "location": "/stexamples/#produce-field-u-kuramoto-sivashinsky", 
            "text": "using   PyPlot  using   TimeseriesPrediction  testdir   =   dirname ( dirname ( pathof ( TimeseriesPrediction ))) * /test  @assert   isdir ( testdir )  include ( testdir * /ks_solver.jl )  Ntrain   =   10000  p   =   100  N   =   Ntrain   +   p  U ,   T   =   KuramotoSivashinsky ( 64 ,   22 ,   N\u00f74 ,   0.25 )  summary ( U )   10101-element Array{Array{Float64,1},1}", 
            "title": "Produce field U (Kuramoto Sivashinsky)"
        }, 
        {
            "location": "/stexamples/#temporal-prediction-of-field-u", 
            "text": "Q   =   length ( U [ 1 ])   # spatial length  pool   =   U [ 1 : Ntrain ]  test   =   U [ Ntrain : N ]  \u03b3   =   10  \u03c4   =   1  B   =   10  k   =   1  ntype   =   FixedMassNeighborhood ( 4 )  method   =   AverageLocalModel ()  em   =   cubic_shell_embedding ( pool ,   \u03b3 , \u03c4 , B , k , PeriodicBoundary ())  pcaem =   PCAEmbedding ( pool , em )  @time   pred   =   temporalprediction ( pool , pcaem ,   p ; ntype = ntype ,   method = method ,   progress   =   false )  err   =   [ abs . ( test [ i ] - pred [ i ])   for   i = 1 : p + 1 ]  println ( Maximum error:  ,   maximum ( maximum ( e )   for   e   in   err ))      3 . 203749   seconds   ( 4 . 12   M   allocations :   278 . 923   MiB ,   12 . 76 %   gc   time )  Maximum   error :   7 . 489722699875914", 
            "title": "Temporal prediction of field U"
        }, 
        {
            "location": "/stexamples/#plot-the-result", 
            "text": "Deduce field extremal values  vmax   =   max ( maximum ( maximum ( s )   for   s   in   test ), \n            maximum ( maximum ( s )   for   s   in   pred ))  vmin   =   min ( minimum ( minimum ( s )   for   s   in   test ), \n            minimum ( minimum ( s )   for   s   in   pred ))   - 5 . 275917990623304   Transform data for imshow  ptest   =   cat ( test ... ,   dims   =   2 )  ppred   =   cat ( pred ... ,   dims   =   2 )  perr   =   cat ( err ... ,   dims   =   2 )   64 \u00d7 101   Array { Float64 , 2 } : \n  0 . 0    0 . 117557       0 . 093332      0 . 0995133     \u2026    0 . 176435    0 . 428045    1 . 12381  \n  0 . 0    0 . 0844138      0 . 0624008     0 . 0627831        1 . 03725     0 . 634373    0 . 149066 \n  0 . 0    0 . 0487361      0 . 0268789     0 . 0249753        1 . 51933     1 . 35378     1 . 12772  \n  0 . 0    0 . 0430553      0 . 00531474    0 . 00402415       1 . 65941     1 . 72697     1 . 76369  \n  0 . 0    0 . 0550993      0 . 00717697    0 . 00488774       1 . 54245     1 . 80927     2 . 07716  \n  0 . 0    0 . 0513383      0 . 0131881     0 . 00198239    \u2026    1 . 27599     1 . 69305     2 . 13234  \n  0 . 0    0 . 0394528      0 . 0126422     0 . 0254385        0 . 977606    1 . 4845      2 . 02576  \n  0 . 0    0 . 0222963      0 . 0454558     0 . 0583722        0 . 749201    1 . 27235     1 . 84884  \n  0 . 0    0 . 0113543      0 . 0875975     0 . 102984         0 . 625136    1 . 10491     1 . 6342   \n  0 . 0    0 . 000283291    0 . 121417      0 . 137955         0 . 64153     1 . 04758     1 . 47385  \n  \u22ee                                           \u22f1                        \u22ee        \n  0 . 0    0 . 0806688      0 . 0717503     0 . 0555449     \u2026    3 . 34076     2 . 8054      2 . 20618  \n  0 . 0    0 . 103009       0 . 0765522     0 . 0773288        4 . 80043     4 . 36622     3 . 83916  \n  0 . 0    0 . 0407499      0 . 0130141     0 . 0274053        5 . 84244     5 . 59799     5 . 24194  \n  0 . 0    0 . 00136207     0 . 0219034     0 . 084694         6 . 28648     6 . 2951      6 . 18903  \n  0 . 0    0 . 0325506      0 . 0315577     0 . 0891074        6 . 06503     6 . 34578     6 . 52844  \n  0 . 0    0 . 0460529      0 . 0990307     0 . 0424581     \u2026    5 . 23427     5 . 75757     6 . 21841  \n  0 . 0    0 . 0623423      0 . 114259      0 . 138285         3 . 96122     4 . 65298     5 . 33638  \n  0 . 0    0 . 0751481      0 . 135083      0 . 139311         2 . 47919     3 . 24312     4 . 04871  \n  0 . 0    0 . 100207       0 . 134398      0 . 130669         1 . 03333     1 . 76527     2 . 57602    plot plot plot  fig   =   figure ( figsize = ( 8 , 8 ))  ax1   =   subplot2grid (( 3 , 1 ),   ( 0 , 0 ))  ax2   =   subplot2grid (( 3 , 1 ),   ( 1 , 0 ))  ax3   =   subplot2grid (( 3 , 1 ),   ( 2 , 0 ));  im1   =   ax1 [ : imshow ]( ppred ,   cmap = viridis ,   vmin   =   vmin ,   vmax   =   vmax ,  aspect   =   auto ,   extent   =   ( T [ Ntrain ],   T [ N ],   1 ,   Q ))  im2   =   ax2 [ : imshow ]( ptest ,   cmap = viridis ,   vmin   =   vmin ,   vmax   =   vmax ,  aspect   =   auto ,   extent   =   ( T [ Ntrain ],   T [ N ],   1 ,   Q ))  im3   =   ax3 [ : imshow ]( perr ,   cmap = inferno ,   vmin   =   0 ,   vmax   =   vmax - vmin ,  aspect   =   auto ,   extent   =   ( T [ Ntrain ],   T [ N ],   1 ,   Q ))  for   ( j ,   ( im ,   ax ))   in   enumerate ( zip ([ im1 , im2 , im3 ],   [ ax1 , ax2 , ax3 ])) \n     colorbar ( im ,   ax   =   ax ,   fraction = 0.04 ,   pad = 0.01 ) # format= %.1f ) \n     if   j     3 \n         ax [ : set_xticklabels ]([]) \n     end  end  ax1 [ : set_title ]( Prediction )  ax2 [ : set_title ]( Real evolution )  ax3 [ : set_title ]( Absolute error )  ax2 [ : set_ylabel ]( space )  ax3 [ : set_xlabel ]( time )  tight_layout ( w_pad = 0.1 ,   h_pad = 0.00001 )   \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   make . jl : 28  \u2514   @   Core   ~/ build / JuliaDynamics / TimeseriesPrediction . jl / docs / make . jl : 28  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   make . jl : 28  \u2514   @   Core   ~/ build / JuliaDynamics / TimeseriesPrediction . jl / docs / make . jl : 28  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   make . jl : 28  \u2514   @   Core   ~/ build / JuliaDynamics / TimeseriesPrediction . jl / docs / make . jl : 28  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 5   [ inlined ]  \u2514   @   Core   . / none : 5  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   make . jl : 28  \u2514   @   Core   ~/ build / JuliaDynamics / TimeseriesPrediction . jl / docs / make . jl : 28  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   make . jl : 28  \u2514   @   Core   ~/ build / JuliaDynamics / TimeseriesPrediction . jl / docs / make . jl : 28  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   make . jl : 28  \u2514   @   Core   ~/ build / JuliaDynamics / TimeseriesPrediction . jl / docs / make . jl : 28  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   make . jl : 28  \u2514   @   Core   ~/ build / JuliaDynamics / TimeseriesPrediction . jl / docs / make . jl : 28  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   make . jl : 28  \u2514   @   Core   ~/ build / JuliaDynamics / TimeseriesPrediction . jl / docs / make . jl : 28", 
            "title": "Plot the result"
        }, 
        {
            "location": "/stexamples/#cross-prediction-barkley-model", 
            "text": "This example cross-predicts a field U from a field V. Both fields have to be represented as vectors of matrices. Where the fields come from does not matter, but to make the example runnable we load one of the test systems of TimeseriesPrediction.  This example uses cubic shell embedding and a linear Barkley model.  Importantly, the results are compared with the \"real\" evolution of the system.", 
            "title": "Cross Prediction: Barkley Model"
        }, 
        {
            "location": "/stexamples/#simulate-a-test-system", 
            "text": "using   PyPlot  using   TimeseriesPrediction  testdir   =   dirname ( dirname ( pathof ( TimeseriesPrediction ))) * /test  @assert   isdir ( testdir )  include ( testdir * /system_defs.jl )  Ttrain   =   500  Ttest   =   10  T   =   Ttrain   +   Ttest  U ,   V   =   barkley ( T ; tskip = 100 ,   ssize = ( 50 , 50 ))  summary ( U )   510-element Array{Array{Float64,2},1}", 
            "title": "Simulate a test system"
        }, 
        {
            "location": "/stexamples/#cross-predict-field-u-from-field-v", 
            "text": "\u03b3   =   5  \u03c4   =   1  B   =   1  k   =   1  bc   =   PeriodicBoundary ()  source_train   =   V [ 1 :   Ttrain ]  target_train   =   U [ 1 :   Ttrain ]  source_pred    =   V [ Ttrain    -   \u03b3 * \u03c4   +   1 :    T ]  target_test    =   U [ Ttrain          +   1 :    T ]  em   =   cubic_shell_embedding ( source_train ,   \u03b3 , \u03c4 , B , k , bc )  pcaem   =   PCAEmbedding ( source_train ,   em ;   maxoutdim = 5 )   # PCA speeds things up!  @time   target_pred   =   crossprediction ( source_train ,   target_train ,   source_pred ,   em ;  progress   =   false )  err   =   [ abs . ( target_test [ i ] - target_pred [ i ])   for   i = 1 : Ttest ]  println ( Maximum error:  ,   maximum ( maximum ( e )   for   e   in   err ))     50 . 487440   seconds   ( 1 . 86   M   allocations :   1 . 178   GiB ,   1 . 31 %   gc   time )  Maximum   error :   0 . 2819220583817802", 
            "title": "Cross predict field U from field V"
        }, 
        {
            "location": "/stexamples/#plot-prediction", 
            "text": "Deduce field extremal values  source_max   =   maximum ( maximum ( s )   for   s   in   source_pred )  target_max   =   max ( maximum ( maximum ( s )   for   s   in   target_test ), \n                  maximum ( maximum ( s )   for   s   in   target_pred ))  source_min   =   minimum ( minimum ( s )   for   s   in   source_pred )  target_min   =   min ( minimum ( minimum ( s )   for   s   in   target_test ), \n                  minimum ( minimum ( s )   for   s   in   target_pred ))   8 . 006923371978363 e - 5   Plot various predicted frames (only the last one shown here)  for   i   in   [ 1 ,   length ( err ) \u00f7 2 ,   length ( err )] \n\n     fig   =   figure ( figsize = ( 10 , 10 )) \n     ax1   =   subplot2grid (( 2 , 2 ),   ( 0 , 0 )) \n     ax2   =   subplot2grid (( 2 , 2 ),   ( 0 , 1 )) \n     ax3   =   subplot2grid (( 2 , 2 ),   ( 1 , 0 )) \n     ax4   =   subplot2grid (( 2 , 2 ),   ( 1 , 1 )) \n     im1   =   ax1 [ : imshow ]( source_pred [ i ],   cmap = viridis ,   vmin   =   source_min ,   vmax   =   source_max ) \n     im2   =   ax2 [ : imshow ]( target_test [ i ],   cmap = cividis ,   vmin   =   target_min ,   vmax   =   target_max ) \n     im3   =   ax3 [ : imshow ]( target_pred [ i ],   cmap = cividis ,   vmin   =   target_min ,   vmax   =   target_max ) \n     im4   =   ax4 [ : imshow ]( err [ i ],   cmap = inferno ,   vmin   =   0 ,   vmax   =   target_max   -   target_min ) \n     for   ( im ,   ax )   in   zip ([ im1 , im2 , im3 , im4 ],   [ ax1 , ax2 , ax3 , ax4 ]) \n         ax [ : get_xaxis ]()[ : set_ticks ]([]) \n         ax [ : get_yaxis ]()[ : set_ticks ]([]) \n         colorbar ( im ,   ax   =   ax ,   fraction = 0.046 ,   pad = 0.04 ) #, format= %.1f ) \n     end \n     ax1 [ : set_title ]( Source ) \n     ax2 [ : set_title ]( Target Test ) \n     ax3 [ : set_title ]( Target Cross-Pred. ) \n     ax4 [ : set_title ]( absolute error ) \n     tight_layout ( w_pad = 0.6 ,   h_pad = 0.00001 ) \n     suptitle ( frame  $i )  end   \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 8  \u2514   @   Core   . / none : 8  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 9   [ inlined ]  \u2514   @   Core   . / none : 9  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 10   [ inlined ]  \u2514   @   Core   . / none : 10  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 11   [ inlined ]  \u2514   @   Core   . / none : 11  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 13   [ inlined ]  \u2514   @   Core   . / none : 13  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 13   [ inlined ]  \u2514   @   Core   . / none : 13  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 14  \u2514   @   Core   . / none : 14  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 14  \u2514   @   Core   . / none : 14  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 17   [ inlined ]  \u2514   @   Core   . / none : 17  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 18   [ inlined ]  \u2514   @   Core   . / none : 18  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 19   [ inlined ]  \u2514   @   Core   . / none : 19  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 20   [ inlined ]  \u2514   @   Core   . / none : 20", 
            "title": "Plot prediction"
        }, 
        {
            "location": "/stexamples/#temporal-prediction-periodic-nonlinear-barkley-model", 
            "text": "This example predicts the temporal evolution of a field U, which has to be represented as vectors of matrices. Where the field comes from does not matter, but to make the example runnable we load one of the test systems of TimeseriesPrediction.  This example uses light cone embedding and a nonlinear Barkley model.  Importantly, the results are compared with the \"real\" evolution of the system.", 
            "title": "Temporal Prediction: Periodic Nonlinear Barkley Model"
        }, 
        {
            "location": "/stexamples/#simulate-a-test-system_1", 
            "text": "using   PyPlot  using   TimeseriesPrediction  testdir   =   dirname ( dirname ( pathof ( TimeseriesPrediction ))) * /test  @assert   isdir ( testdir )  include ( testdir * /system_defs.jl )  Ttrain   =   300  Ttest   =   5  T   =   Ttrain   +   Ttest  init   =   [   0.6241      0.589685    0.668221     0.194882      0.687645 \n          0.656243    0.702544    0.476963     0.00236098    0.636111 \n          0.821854    0.868514    0.242682     0.2588        0.30552 \n          0.580972    0.355305    0.0805268    0.501724      0.728142 \n          0.297559    0.708676    0.583552     0.65363       0.555639 ]  U ,   V   =   barkley ( T ;   tskip = 100 ,   ssize = ( 50 , 50 ),   init   =   init )  summary ( U )   305-element Array{Array{Float64,2},1}", 
            "title": "Simulate a test system"
        }, 
        {
            "location": "/stexamples/#temporal-prediction-of-field-u_1", 
            "text": "\u03b3   =   2  \u03c4   =   1  r   =   1  c   =   1  bc   =   PeriodicBoundary ()  pool   =   U [ 1   :   Ttrain ]  test    =   U [   Ttrain   :   T ]  em   =   light_cone_embedding ( pool ,   \u03b3 , \u03c4 , r , c , bc )  pcaem   =   PCAEmbedding ( pool ,   em ;   maxoutdim = 5 )   # PCA speeds things up!  @time   pred   =   temporalprediction ( pool ,   em ,   Ttest ;   progress   =   false )  err   =   [ abs . ( test [ i ] - pred [ i ])   for   i = 1 : Ttest + 1 ]  println ( Maximum error:  ,   maximum ( maximum ( e )   for   e   in   err ))     25 . 033708   seconds   ( 1 . 72   M   allocations :   931 . 762   MiB ,   1 . 73 %   gc   time )  Maximum   error :   0 . 2934269941090367", 
            "title": "Temporal prediction of field U"
        }, 
        {
            "location": "/stexamples/#plot-prediction_1", 
            "text": "Deduce field maximum values  vmax   =   max ( maximum ( maximum ( s )   for   s   in   test ), \n            maximum ( maximum ( s )   for   s   in   pred ))  vmin   =   min ( minimum ( minimum ( s )   for   s   in   test ), \n            minimum ( minimum ( s )   for   s   in   pred ))   0 . 0015249975046802136   plot plot plot  for   i   in   [ 1 ,   length ( err ) \u00f7 2 ,   length ( err )] \n\n     fig   =   figure ( figsize = ( 10 , 3 )) \n     ax1   =   subplot2grid (( 1 , 3 ),   ( 0 , 0 )) \n     ax2   =   subplot2grid (( 1 , 3 ),   ( 0 , 1 )) \n     ax3   =   subplot2grid (( 1 , 3 ),   ( 0 , 2 )) \n\n     im1   =   ax1 [ : imshow ]( pred [ i ],   cmap = viridis ,   vmin   =   vmin ,   vmax   =   vmax ) \n     im2   =   ax2 [ : imshow ]( test [ i ],   cmap = viridis ,   vmin   =   vmin ,   vmax   =   vmax ) \n     im3   =   ax3 [ : imshow ]( err [ i ],   cmap = inferno ,   vmin   =   0 ,   vmax   =   vmax - vmin ) \n     for   ( im ,   ax )   in   zip ([ im1 , im2 , im3 ],   [ ax1 , ax2 , ax3 ]) \n         ax [ : get_xaxis ]()[ : set_ticks ]([]) \n         ax [ : get_yaxis ]()[ : set_ticks ]([]) \n         colorbar ( im ,   ax   =   ax ,   fraction = 0.046 ,   pad = 0.04 ) #, format= %.1f ) \n     end \n     ax1 [ : set_title ]( Prediction ) \n     ax2 [ : set_title ]( Real evolution ) \n     ax3 [ : set_title ]( Absolute error ) \n     suptitle ( frame  $i ) \n     tight_layout ( w_pad = 0.6 ,   h_pad = 0.00001 ) \n     subplots_adjust ( top = 0.75 )  end   \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 8   [ inlined ]  \u2514   @   Core   . / none : 8  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 9  \u2514   @   Core   . / none : 9  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 10   [ inlined ]  \u2514   @   Core   . / none : 10  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 12   [ inlined ]  \u2514   @   Core   . / none : 12  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 12   [ inlined ]  \u2514   @   Core   . / none : 12  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 13  \u2514   @   Core   . / none : 13  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 13  \u2514   @   Core   . / none : 13  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 16   [ inlined ]  \u2514   @   Core   . / none : 16  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 17   [ inlined ]  \u2514   @   Core   . / none : 17  \u250c   Warning :   `getindex(o::PyObject, s::Symbol)`   is   deprecated   in   favor   of   dot   overloading   ( `getproperty` )   so   elements   should   now   be   accessed   as   e . g .   `o.s`   instead   of   `o[:s]` .  \u2502     caller   =   top - level   scope   at   none : 18   [ inlined ]  \u2514   @   Core   . / none : 18    This page was generated using  Literate.jl .", 
            "title": "Plot prediction"
        }, 
        {
            "location": "/symmetry/", 
            "text": "Exploiting Spatial Symmetries\n\n\nSome systems have symmetries that apply to their spatial dimensions. For example, the cubic Barkley model has equations:\n\n\n\n\n\nu_t = \\frac{1}{\\epsilon}u(1-u)(u-\\frac{v+b}{a}) + \\nabla^2 u \\\\\nv_t = u^3 - v\n\n\n\n\nu_t = \\frac{1}{\\epsilon}u(1-u)(u-\\frac{v+b}{a}) + \\nabla^2 u \\\\\nv_t = u^3 - v\n\n\n\n\n\nThe only spatial coupling component is the Laplacian operator, \n\\nabla^2\n\\nabla^2\n. This means that the equations of the Barkley model have rotational symmetry with respect to space.\n\n\nIn principle one should be able to take advantage of these symmetries to reduce the embedded space dimension.\n\n\n\n\nSymmetries\n\n\nWe encode symmetries with the following types:\n\n\n#\n\n\nTimeseriesPrediction.Symmetry\n \n \nType\n.\n\n\nSymmetry\n\n\n\n\n\n\nSupertype of all symmetries used in \nSymmetricEmbedding\n. All symmetries are initialized like \nSymmetry(n1, n2, ...)\n with \nni\n being the indices of the spatial dimensions that have the said symmetry.\n\n\nNotice that the symmetries are defined with respect to the center point of the embedding.\n\n\nsource\n\n\n#\n\n\nTimeseriesPrediction.Reflection\n \n \nType\n.\n\n\nReflection\n \n:\n \nSymmetry\n\n\n\n\n\n\nReflection symmetry: x and -x are equivalent (for all given dimensions).\n\n\nsource\n\n\n#\n\n\nTimeseriesPrediction.Rotation\n \n \nType\n.\n\n\nRotation\n \n:\n \nSymmetry\n\n\n\n\n\n\nIndex sets at equal distance from the center point are equivalent, for the given input dimensions. E.g. for \nRotation(1,3)\n and given center point \nu[i,j,k,...]\n all indices \nm, n\n that satisfy\n\n\n|\ni\n-\nm\n|^\n2\n \n+\n \n|\nk\n-\nn\n|^\n2\n \n=\n \nr\n^\n2\n\n\n\n\n\n\nfor a given \nr\n, are equivalent. The same process generalizes to any number of input dimensions.\n\n\nsource\n\n\n\n\nSymmetric Embedding\n\n\nYou can use the symmetries in the following embedding:\n\n\n#\n\n\nTimeseriesPrediction.SymmetricEmbedding\n \n \nType\n.\n\n\nSymmetricEmbedding\n(\nste\n::\nSpatioTemporalEmbedding\n,\n \nsym\n::\nTuple\n)\n\n\n\n\n\n\nA \nSymmetricEmbedding\n is intended as a means of dimension reduction for a \nSpatioTemporalEmbedding\n by exploiting spatial symmetries in the system, listed as a \nTuple\n of \n:Symmetry\n (see \nSymmetry\n) for all possible symmetries.\n\n\nAll points at a time step equivalent to each other according to the symmetries passed in \nsym\n will be \naveraged\n to a single entry! For example, the symmetry \nReflection(2)\n means that the embedding won't have two entries \nu[i, j+1], u[i, j-1]\n but instead a single entry \n(u[i, j+1] + u[i, j-1])/2\n, with \ni,j\n being indices \nrelative to the central point of the embedding\n. (the same process is done for any index offset \nj+2, j+3\n, etc., depending on how large the spatial radius \nr\n is)\n\n\nThe resulting structure from \nSymmetricEmbedding\n can be used for reconstructing datasets in the same way as a \nSpatioTemporalEmbedding\n.\n\n\nsource", 
            "title": "Exploiting Spatial Symmetries"
        }, 
        {
            "location": "/symmetry/#exploiting-spatial-symmetries", 
            "text": "Some systems have symmetries that apply to their spatial dimensions. For example, the cubic Barkley model has equations:   \nu_t = \\frac{1}{\\epsilon}u(1-u)(u-\\frac{v+b}{a}) + \\nabla^2 u \\\\\nv_t = u^3 - v  \nu_t = \\frac{1}{\\epsilon}u(1-u)(u-\\frac{v+b}{a}) + \\nabla^2 u \\\\\nv_t = u^3 - v   The only spatial coupling component is the Laplacian operator,  \\nabla^2 \\nabla^2 . This means that the equations of the Barkley model have rotational symmetry with respect to space.  In principle one should be able to take advantage of these symmetries to reduce the embedded space dimension.", 
            "title": "Exploiting Spatial Symmetries"
        }, 
        {
            "location": "/symmetry/#symmetries", 
            "text": "We encode symmetries with the following types:  #  TimeseriesPrediction.Symmetry     Type .  Symmetry   Supertype of all symmetries used in  SymmetricEmbedding . All symmetries are initialized like  Symmetry(n1, n2, ...)  with  ni  being the indices of the spatial dimensions that have the said symmetry.  Notice that the symmetries are defined with respect to the center point of the embedding.  source  #  TimeseriesPrediction.Reflection     Type .  Reflection   :   Symmetry   Reflection symmetry: x and -x are equivalent (for all given dimensions).  source  #  TimeseriesPrediction.Rotation     Type .  Rotation   :   Symmetry   Index sets at equal distance from the center point are equivalent, for the given input dimensions. E.g. for  Rotation(1,3)  and given center point  u[i,j,k,...]  all indices  m, n  that satisfy  | i - m |^ 2   +   | k - n |^ 2   =   r ^ 2   for a given  r , are equivalent. The same process generalizes to any number of input dimensions.  source", 
            "title": "Symmetries"
        }, 
        {
            "location": "/symmetry/#symmetric-embedding", 
            "text": "You can use the symmetries in the following embedding:  #  TimeseriesPrediction.SymmetricEmbedding     Type .  SymmetricEmbedding ( ste :: SpatioTemporalEmbedding ,   sym :: Tuple )   A  SymmetricEmbedding  is intended as a means of dimension reduction for a  SpatioTemporalEmbedding  by exploiting spatial symmetries in the system, listed as a  Tuple  of  :Symmetry  (see  Symmetry ) for all possible symmetries.  All points at a time step equivalent to each other according to the symmetries passed in  sym  will be  averaged  to a single entry! For example, the symmetry  Reflection(2)  means that the embedding won't have two entries  u[i, j+1], u[i, j-1]  but instead a single entry  (u[i, j+1] + u[i, j-1])/2 , with  i,j  being indices  relative to the central point of the embedding . (the same process is done for any index offset  j+2, j+3 , etc., depending on how large the spatial radius  r  is)  The resulting structure from  SymmetricEmbedding  can be used for reconstructing datasets in the same way as a  SpatioTemporalEmbedding .  source", 
            "title": "Symmetric Embedding"
        }
    ]
}